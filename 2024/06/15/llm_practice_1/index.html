<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>LLM实践:意图识别下的LLM与传统模型 | QianLi Yang</title><meta name="author" content="QianLi Yang"><meta name="copyright" content="QianLi Yang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="在实习工作中遇到过许多意图识别的场景，在LLM阶段似乎为复杂意图识别任务提供了可能性，但是事实真是如此吗？ 受到腾讯混元团队结论的启发：在意图识别、实体抽取等任务上，还是不如传统的小模型做的好，除非意图识别很复杂的，或者实体抽取很复杂的内容，这种情况小模型也做不好 于是在这里打算以几个场景来通过实验论证 常见场景 文本内容超过小模型处理长度 任务需要复杂推理能力  实验设计 复杂任务下的意图识别">
<meta property="og:type" content="article">
<meta property="og:title" content="LLM实践:意图识别下的LLM与传统模型">
<meta property="og:url" content="http://example.com/2024/06/15/llm_practice_1/index.html">
<meta property="og:site_name" content="QianLi Yang">
<meta property="og:description" content="在实习工作中遇到过许多意图识别的场景，在LLM阶段似乎为复杂意图识别任务提供了可能性，但是事实真是如此吗？ 受到腾讯混元团队结论的启发：在意图识别、实体抽取等任务上，还是不如传统的小模型做的好，除非意图识别很复杂的，或者实体抽取很复杂的内容，这种情况小模型也做不好 于是在这里打算以几个场景来通过实验论证 常见场景 文本内容超过小模型处理长度 任务需要复杂推理能力  实验设计 复杂任务下的意图识别">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/images/head.jpg">
<meta property="article:published_time" content="2024-06-15T12:44:48.000Z">
<meta property="article:modified_time" content="2025-01-26T14:16:49.274Z">
<meta property="article:author" content="QianLi Yang">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/head.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2024/06/15/llm_practice_1/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'LLM实践:意图识别下的LLM与传统模型',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/images/head.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">6</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">2</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://github.com/YangQianli92"><i class="fa-fw fab fa-github"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">QianLi Yang</span></a><a class="nav-page-title" href="/"><span class="site-name">LLM实践:意图识别下的LLM与传统模型</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://github.com/YangQianli92"><i class="fa-fw fab fa-github"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">LLM实践:意图识别下的LLM与传统模型</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-06-15T12:44:48.000Z" title="发表于 2024-06-15 20:44:48">2024-06-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-01-26T14:16:49.274Z" title="更新于 2025-01-26 22:16:49">2025-01-26</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>在实习工作中遇到过许多意图识别的场景，在LLM阶段似乎为复杂意图识别任务提供了可能性，但是事实真是如此吗？</p>
<p>受到腾讯混元团队结论的启发：<em><strong>在意图识别、实体抽取等任务上，还是不如传统的小模型做的好，除非意图识别很复杂的，或者实体抽取很复杂的内容，这种情况小模型也做不好</strong></em></p>
<p>于是在这里打算以几个场景来通过实验论证</p>
<h2 id="常见场景"><a href="#常见场景" class="headerlink" title="常见场景"></a>常见场景</h2><ol>
<li>文本内容超过小模型处理长度</li>
<li>任务需要复杂推理能力</li>
</ol>
<h2 id="实验设计"><a href="#实验设计" class="headerlink" title="实验设计"></a>实验设计</h2><ol>
<li>复杂任务下的意图识别</li>
<li>简单任务下的意图识别</li>
</ol>
<h2 id="实验过程"><a href="#实验过程" class="headerlink" title="实验过程"></a>实验过程</h2><h3 id="数据介绍及预处理"><a href="#数据介绍及预处理" class="headerlink" title="数据介绍及预处理"></a>数据介绍及预处理</h3><ol>
<li>腾讯业内场景数据，意图识别，5个类别，涉及到复杂逻辑推理，训练2K条，测试1K条</li>
<li>Standford&#x2F;imdb,二分类，简单任务</li>
</ol>
<h3 id="模型选取"><a href="#模型选取" class="headerlink" title="模型选取"></a>模型选取</h3><ol>
<li>Qwen&#x2F;Qwen2.5-14B-Instruct</li>
<li>FacebookAI&#x2F;xlm-roberta-large</li>
<li>SequenceClassificationModel(Qwen2.5-14B-Instruct)冻结主干，微调分类头</li>
<li>LoRA(Qwen2.5-14B-Instruct)  </li>
<li>FUll SFT(Qwen2.5-14B-Instruct)</li>
</ol>
<h3 id="实验结论"><a href="#实验结论" class="headerlink" title="实验结论"></a>实验结论</h3><h4 id="任务1"><a href="#任务1" class="headerlink" title="任务1"></a>任务1</h4><table>
<thead>
<tr>
<th>Model</th>
<th>Accuracy</th>
</tr>
</thead>
<tbody><tr>
<td>Model1</td>
<td>0.7670</td>
</tr>
<tr>
<td>Model2</td>
<td>0.6125</td>
</tr>
<tr>
<td>Model3</td>
<td>0.6733</td>
</tr>
<tr>
<td>Model4</td>
<td>0.9491</td>
</tr>
<tr>
<td>Model4</td>
<td>0.9516</td>
</tr>
</tbody></table>
<p>结果表明，对于具有需要逻辑推理能力的任务，小模型无法胜任，而LLM使用SequenceClassificationModel能力会退化和BERT类似<br>经过SFT（LoRA、Full） 的模型表现良好</p>
<h4 id="任务2"><a href="#任务2" class="headerlink" title="任务2"></a>任务2</h4><p><a target="_blank" rel="noopener" href="https://huggingface.co/blog/zh/Lora-for-sequence-classification-with-Roberta-Llama-Mistral">https://huggingface.co/blog/zh/Lora-for-sequence-classification-with-Roberta-Llama-Mistral</a><br>参考这篇文章</p>
<h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Hello World&#x27;</span>)</span><br></pre></td></tr></table></figure></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">QianLi Yang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://yangqianli92.github.io/">https://yangqianli92.github.io/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">QianLi Yang</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/LLM/">LLM</a></div><div class="post-share"><div class="social-share" data-image="/images/head.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/2024/06/15/surfpronn/" title="SurfPro-NN:A 3D Point Cloud Neural Network for the scoring of protein–protein docking models based on Surfaces features and Protein language models"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">SurfPro-NN:A 3D Point Cloud Neural Network for the scoring of protein–protein docking models based on Surfaces features and Protein language models</div></div><div class="info-2"><div class="info-item-1">IntroductionProtein–protein interactions (PPI) play a crucial role in numerous key biological processes, and the structure of protein complexes provides valuable clues for in-depth exploration of molecular-level biological processes. Protein–protein docking technology is widely used to simulate the spatial structure of proteins. However, there are still challenges in selecting candidate decoys that closely resemble the native structure from protein–protein docking simulations. In this study,...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/05/29/function_calling/" title="LLM实践:function calling工具调用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-29</div><div class="info-item-2">LLM实践:function calling工具调用</div></div><div class="info-2"><div class="info-item-1">本章目录 目录 1. 工具调用示例 2.Function calling 数据 2.1 无Function的示例 2.2 有Function的示例 2.3 Function Call时SFT [3. Agent Tool、Function Call和MCP的关系](#Agent Tool、Function Call和MCP的关系) 4. MCP详解 4.1 MCP中模型是如何选择工具的 4.2 MCP是如何使用工具的  Function Calling工具使用，也称为函数调用(Function calling)，是指通过定义和调用外部工具或函数来扩展大模型的能力。我们可以为大模型提供一组预定义工具的访问权限，它可以随时调用这些工具。工具允许我们编写代码，这些代码可以执行大模型无法执行的特定任务或计算。简而言之：工具使用是增强大模型功能的一种方式。  工具调用通常具有以下几个特性：1 拓展大模型的功能：使用工具可以让大模型的功能超越其内置功能。通过定义和调用外部工具，您可以使大模型能够执行原本无法完成的任务 2 与现有系统集成：使用工具可以实现大模型与您现有系统、数据库或 API...</div></div></div></a><a class="pagination-related" href="/2025/01/26/llm_nope/" title="LLM实践2:大模型长度外推简单实践"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-01-26</div><div class="info-item-2">LLM实践2:大模型长度外推简单实践</div></div><div class="info-2"><div class="info-item-1">暑期实习的时候面试经常碰到面试官问如何拓展LLM的上下文，现在已经是标准的八股回答：Dynamic NTK，NTK Aware插值，YaRN等方法但是有的需要设计到微调，则比较麻烦，也有部分方法不需要微调，但是也没有系统性验证过可行性，现在闲来无事想利用空闲时间跑跑代码看看效果   具体的理论细节可以参考这篇博客：https://blog.csdn.net/v_JULY_v/article/details/135072211 本次实验采用LLaMA-2-7B,数据使用BAAI提供的数据，随机抽样了5000条进行预训练or推理 本实验将使用LLaMA_Factory&#x3D;&#x3D;0.9.1, transformers&#x3D;&#x3D;4.46.1,显卡为NVIDIA A100-PCIE-40GB * 2max length&#x3D;8K，batch_size&#x3D;1,epoch&#x3D;1 GPU20GB ~ 30GB   实验结论   RoPE Type Max Length Training Loss Training Loss...</div></div></div></a><a class="pagination-related" href="/2025/05/13/langrensha/" title="LLM实践:基于LLM的狼人杀文字版游戏"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-13</div><div class="info-item-2">LLM实践:基于LLM的狼人杀文字版游戏</div></div><div class="info-2"><div class="info-item-1">游戏流程详细介绍整个狼人杀游戏的流程主要由 GameManager 类和 RoleAIManager 类协同完成，以下是详细的游戏流程： 1. 游戏初始化GameManager 初始化：在 GameManager 类的 __init__ 方法中，设置游戏的基本信息，如游戏 ID、轮次、日夜状态、玩家角色配置、存活玩家列表、死亡玩家记录等。角色分配：调用 startup 方法，随机分配玩家角色，并为每个玩家创建对应的 RoleAIManager 对象。同时，记录每个角色对应的玩家编号，以及每个玩家的真实角色。 2. 夜晚阶段狼人行动：在 act_at_night 方法中，首先处理狼人杀人。存活的狼人玩家通过 RoleAIManager 的 act_at_night 方法进行思考和投票，选择要杀的玩家。最后，随机选取一个得票最多的玩家作为被杀对象。预言家行动：存活的预言家玩家通过 RoleAIManager 的 act_at_night 方法进行思考和查看，选择要查验的玩家，并得知其身份。女巫行动：存活的女巫玩家根据狼人杀人情况，通过 RoleAIManager 的...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/images/head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">QianLi Yang</div><div class="author-info-description">不定时更新程序员成长之路~</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">6</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">2</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/YangQianli92" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:chainllie92@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/Serein_Young" target="_blank" title="Wechat"><i class="fab fa-weixin"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E5%9C%BA%E6%99%AF"><span class="toc-number">1.</span> <span class="toc-text">常见场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E8%AE%BE%E8%AE%A1"><span class="toc-number">2.</span> <span class="toc-text">实验设计</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E8%BF%87%E7%A8%8B"><span class="toc-number">3.</span> <span class="toc-text">实验过程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E4%BB%8B%E7%BB%8D%E5%8F%8A%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">3.1.</span> <span class="toc-text">数据介绍及预处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E9%80%89%E5%8F%96"><span class="toc-number">3.2.</span> <span class="toc-text">模型选取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E8%AE%BA"><span class="toc-number">3.3.</span> <span class="toc-text">实验结论</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A11"><span class="toc-number">3.3.1.</span> <span class="toc-text">任务1</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A12"><span class="toc-number">3.3.2.</span> <span class="toc-text">任务2</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3"><span class="toc-number">4.</span> <span class="toc-text">解决</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/05/29/function_calling/" title="LLM实践:function calling工具调用">LLM实践:function calling工具调用</a><time datetime="2025-05-29T12:44:48.000Z" title="发表于 2025-05-29 20:44:48">2025-05-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/05/13/langrensha/" title="LLM实践:基于LLM的狼人杀文字版游戏">LLM实践:基于LLM的狼人杀文字版游戏</a><time datetime="2025-05-13T12:44:48.000Z" title="发表于 2025-05-13 20:44:48">2025-05-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/01/26/llm_nope/" title="LLM实践2:大模型长度外推简单实践">LLM实践2:大模型长度外推简单实践</a><time datetime="2025-01-26T05:54:00.000Z" title="发表于 2025-01-26 13:54:00">2025-01-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/10/03/pbgpt/" title="PB-GPT:An innovative GPT-based model for protein backbone generation">PB-GPT:An innovative GPT-based model for protein backbone generation</a><time datetime="2024-10-03T12:44:48.000Z" title="发表于 2024-10-03 20:44:48">2024-10-03</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/06/15/surfpronn/" title="SurfPro-NN:A 3D Point Cloud Neural Network for the scoring of protein–protein docking models based on Surfaces features and Protein language models">SurfPro-NN:A 3D Point Cloud Neural Network for the scoring of protein–protein docking models based on Surfaces features and Protein language models</a><time datetime="2024-06-15T12:44:48.000Z" title="发表于 2024-06-15 20:44:48">2024-06-15</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By QianLi Yang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>