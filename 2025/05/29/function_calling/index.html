<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>LLM实践:function calling工具调用 | QianLi Yang</title><meta name="author" content="QianLi Yang"><meta name="copyright" content="QianLi Yang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Function Calling工具使用，也称为函数调用(Function calling)，是指通过定义和调用外部工具或函数来扩展大模型的能力。我们可以为大模型提供一组预定义工具的访问权限，它可以随时调用这些工具。工具允许我们编写代码，这些代码可以执行大模型无法执行的特定任务或计算。简而言之：工具使用是增强大模型功能的一种方式。  工具调用通常具有以下几个特性：1 拓展大模型的功能：使用工具可以">
<meta property="og:type" content="article">
<meta property="og:title" content="LLM实践:function calling工具调用">
<meta property="og:url" content="http://example.com/2025/05/29/function_calling/index.html">
<meta property="og:site_name" content="QianLi Yang">
<meta property="og:description" content="Function Calling工具使用，也称为函数调用(Function calling)，是指通过定义和调用外部工具或函数来扩展大模型的能力。我们可以为大模型提供一组预定义工具的访问权限，它可以随时调用这些工具。工具允许我们编写代码，这些代码可以执行大模型无法执行的特定任务或计算。简而言之：工具使用是增强大模型功能的一种方式。  工具调用通常具有以下几个特性：1 拓展大模型的功能：使用工具可以">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/images/head.jpg">
<meta property="article:published_time" content="2025-05-29T12:44:48.000Z">
<meta property="article:modified_time" content="2025-06-03T04:41:06.379Z">
<meta property="article:author" content="QianLi Yang">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/head.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2025/05/29/function_calling/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'LLM实践:function calling工具调用',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/images/head.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">17</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://github.com/YangQianli92"><i class="fa-fw fab fa-github"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">QianLi Yang</span></a><a class="nav-page-title" href="/"><span class="site-name">LLM实践:function calling工具调用</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://github.com/YangQianli92"><i class="fa-fw fab fa-github"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">LLM实践:function calling工具调用</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-05-29T12:44:48.000Z" title="发表于 2025-05-29 20:44:48">2025-05-29</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-06-03T04:41:06.379Z" title="更新于 2025-06-03 12:41:06">2025-06-03</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="Function-Calling"><a href="#Function-Calling" class="headerlink" title="Function Calling"></a>Function Calling</h1><p>工具使用，也称为函数调用(Function calling)，是指通过定义和调用外部工具或函数来扩展大模型的能力。<br>我们可以为大模型提供一组预定义工具的访问权限，它可以随时调用这些工具。<br>工具允许我们编写代码，这些代码可以执行大模型无法执行的特定任务或计算。<br>简而言之：工具使用是增强大模型功能的一种方式。</p>
<p><img src="/images/function_call_pipeline.png" alt="Function call基本流程"></p>
<p>工具调用通常具有以下几个特性：<br>1 拓展大模型的功能：使用工具可以让大模型的功能超越其内置功能。通过定义和调用外部工具，您可以使大模型能够执行原本无法完成的任务</p>
<p>2 与现有系统集成：使用工具可以实现大模型与您现有系统、数据库或 API 的无缝集成</p>
<p>3 自动化工作流：借助工具使用，您可以自动化涉及多个步骤或需要专门计算的复杂任务和工作流。通过定义封装这些任务的工具，您可以简化流程、减少人工操作并提高效率。</p>
<p>先前做一些工作的时候会遇到以下场景：</p>
<ol>
<li><p>数值计算：由于大模型本身的数学计算能力一般，遇到一些需要数学计算时，常常表现的不尽人意，特别是小一点的模型，例如游戏得分、金币计算等<br>做一些加减乘除容易犯错，此时可以利用大模型的逻辑能力，提供需要计算的参数，然后利用外置工具例如计算器或者自定义的一些函数，<br>这样可以确保计算准确</p>
</li>
<li><p>API&#x2F;数据库查询：有时候在工作流中遇到需要及时查询的情况，例如查询当下时间、查询某时刻某表的具体数值，此时大模型可以利用工具进行查询，提升效率</p>
</li>
<li><p>自动化工作流： 有时候一些工作流可以基于Function call和Agent去实现，例如简单的表格增删改查等</p>
</li>
</ol>
<p>其实最常见的还是数值计算，API、SQL查询不是很靠谱，之前跑过一些Benchmark和业务上的需求，实际效果远不如论文中的水平。<br>特别是涉及多表查询、多个数值计算等</p>
<h2 id="工具调用示例"><a href="#工具调用示例" class="headerlink" title="工具调用示例"></a>工具调用示例</h2><p>以下是一个工具调用的示例，以DeepSeek-V3为例，该模型具备一定的Function能力,我们定义了两个工具，查询天气和查询时间</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line">API_KEY = <span class="string">&quot;YOUR-API_KEY&quot;</span></span><br><span class="line">BASE_URL = <span class="string">&quot;YOUR-BASE_URL&quot;</span></span><br><span class="line"></span><br><span class="line">client = OpenAI(api_key=API_KEY, base_url=BASE_URL)</span><br><span class="line"></span><br><span class="line">weather_tool = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">        <span class="string">&quot;function&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;get_weather&quot;</span>,</span><br><span class="line">            <span class="string">&quot;description&quot;</span>: <span class="string">&quot;Get weather of an location, the user shoud supply a location first&quot;</span>,</span><br><span class="line">            <span class="string">&quot;parameters&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>,</span><br><span class="line">                <span class="string">&quot;properties&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;location&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;description&quot;</span>: <span class="string">&quot;The city and state, e.g. San Francisco, CA&quot;</span>,</span><br><span class="line">                    &#125;,</span><br><span class="line">                    <span class="string">&#x27;time&#x27;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;description&quot;</span>: <span class="string">&quot;The date of the weather, e.g. 2019-05-21&quot;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="string">&quot;required&quot;</span>: [<span class="string">&quot;location&quot;</span>,<span class="string">&#x27;time&#x27;</span>]</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">        <span class="string">&quot;function&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;get_date&quot;</span>,</span><br><span class="line">            <span class="string">&quot;description&quot;</span>: <span class="string">&quot;Get the present time&quot;</span>,</span><br><span class="line">            <span class="string">&quot;parameters&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>,</span><br><span class="line">                <span class="string">&quot;properties&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;type&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;enum&quot;</span>: [<span class="string">&quot;Second&quot;</span>, <span class="string">&quot;Minute&quot;</span>, <span class="string">&quot;Day&quot;</span>],</span><br><span class="line">                        <span class="string">&quot;description&quot;</span>: <span class="string">&quot;The granularity of the query&quot;</span>,</span><br><span class="line">                    &#125;,</span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="string">&quot;required&quot;</span>: [<span class="string">&quot;type&quot;</span>]</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">response = client.chat.completions.create(</span><br><span class="line">    model=<span class="string">&quot;deepseek-v3-241226&quot;</span>,</span><br><span class="line">    messages=[</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;You are a helpful assistant&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;广州今天的天气如何？&quot;</span>&#125;,</span><br><span class="line">    ],</span><br><span class="line">    max_tokens=<span class="number">100</span>,</span><br><span class="line">    tools=weather_tool</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">tool_calls = response.choices[<span class="number">0</span>].message.tool_calls</span><br><span class="line"><span class="keyword">for</span> tool_call <span class="keyword">in</span> tool_calls:</span><br><span class="line">    <span class="built_in">print</span>(tool_call.function)</span><br></pre></td></tr></table></figure>

<p>对应结果是：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Function(arguments=&#x27;&#123;&quot;type&quot;:&quot;Day&quot;&#125;&#x27;, name=&#x27;get<span class="emphasis">_date&#x27;)</span></span><br><span class="line"><span class="emphasis">Function(arguments=&#x27;&#123;&quot;location&quot;:&quot;广州&quot;,&quot;time&quot;:&quot;2023-10-07&quot;&#125;&#x27;, name=&#x27;get_</span>weather&#x27;)</span><br></pre></td></tr></table></figure>

<p>如果只使用一个LLM调用，LLM会按顺序输出tools调用编排顺序以及参数，但可以看到这里time并不是实时的结果，<br>因此对于这种嵌套调用 通常可以使用以下方法实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> wikipedia</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Tools</span>:</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_article</span>(<span class="params">self, search_term</span>):</span><br><span class="line">        results = wikipedia.search(search_term)</span><br><span class="line">        first_result = results[<span class="number">0</span>]</span><br><span class="line">        page = wikipedia.page(first_result, auto_suggest=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">return</span> page.content</span><br><span class="line">tools = Tools()</span><br><span class="line"></span><br><span class="line">article_search_tool = &#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">    <span class="string">&quot;function&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;name&quot;</span>: <span class="string">&quot;get_article&quot;</span>,</span><br><span class="line">        <span class="string">&quot;description&quot;</span>: <span class="string">&quot;A tool to retrieve an up to date Wikipedia article.&quot;</span>,</span><br><span class="line">        <span class="string">&quot;parameters&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>,</span><br><span class="line">            <span class="string">&quot;properties&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;search_term&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;description&quot;</span>: <span class="string">&quot;The search term to find a wikipedia article by title&quot;</span></span><br><span class="line">                &#125;,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;required&quot;</span>: [<span class="string">&quot;search_term&quot;</span>]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response = client.chat.completions.create(</span><br><span class="line">    model=<span class="string">&quot;deepseek-v3-241226&quot;</span>,</span><br><span class="line">    messages=[</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;You are a helpful assistant&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;Could you please help me look up NetEase Interactive Entertainment&quot;</span>&#125;,</span><br><span class="line">    ],</span><br><span class="line">    max_tokens=<span class="number">100</span>,</span><br><span class="line">    tools=[article_search_tool]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># title = list(json.loads(response.choices[0].message.tool_calls[0].function.arguments).values())[0]</span></span><br><span class="line">args = json.loads(response.choices[<span class="number">0</span>].message.tool_calls[<span class="number">0</span>].function.arguments</span><br><span class="line">tool_name = response.choices[<span class="number">0</span>].message.tool_calls[<span class="number">0</span>].function.name</span><br><span class="line">method_obj = <span class="built_in">getattr</span>(tools, tool_name)</span><br><span class="line">article = method_obj(**args)</span><br><span class="line"><span class="built_in">print</span>(article[:<span class="number">500</span>]) </span><br></pre></td></tr></table></figure>

<p>以下是输出，这样可以将</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">NetEase, Inc. (simplified Chinese: 网易; traditional Chinese: 網易; pinyin: Wǎngyì; Jyutping: mong5 ji6) is a Chinese Internet technology company founded by Ding Lei in June 1997. It provides online services with content, community, communications, and commerce. The company develops and operates online PC and mobile games, advertising services, email services, and e-commerce platforms in China. It is one of the largest Internet and video game companies in the world. The company owns multiple pig far</span><br></pre></td></tr></table></figure>

<p>以上实例将具体的方法抽象到一个类中，然后LLM进过思考选择工具调用，然后指定工具名称和参数，这样可以自动实现tools静态方法获得结果。至此我们就完成了一次完整的Function calling运行流程。</p>
<h2 id="Function-calling数据"><a href="#Function-calling数据" class="headerlink" title="Function-calling数据"></a>Function-calling数据</h2><p>通常Function&#x2F;Tool 都需要以JSON格式输入给大模型 这里有一些 <a target="_blank" rel="noopener" href="https://json-schema.org/learn/getting-started-step-by-step">JSON Schema的教程</a></p>
<p>本小节来源：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/674859843">https://zhuanlan.zhihu.com/p/674859843</a><br>相关文章： <a target="_blank" rel="noopener" href="https://deepseek.csdn.net/67fd1c91e47cbf761b5a0b77.html">https://deepseek.csdn.net/67fd1c91e47cbf761b5a0b77.html</a></p>
<h3 id="无Function的示例"><a href="#无Function的示例" class="headerlink" title="无Function的示例"></a>无Function的示例</h3><p>以Qwen为例，一个推理和多轮对话的模板如下所示：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;|im<span class="emphasis">_start|&gt;system</span></span><br><span class="line"><span class="emphasis">You are a helpful assistant.&lt;|im_</span>end|&gt;</span><br><span class="line">&lt;|im<span class="emphasis">_start|&gt;user</span></span><br><span class="line"><span class="emphasis">你好&lt;|im_</span>end|&gt;</span><br><span class="line">&lt;|im<span class="emphasis">_start|&gt;assistant</span></span><br><span class="line"><span class="emphasis">你好！很高兴为你提供帮助。&lt;|im_</span>end|&gt;</span><br><span class="line">&lt;|im<span class="emphasis">_start|&gt;user</span></span><br><span class="line"><span class="emphasis">给我讲一下网易的发展史。&lt;|im_</span>end|&gt;</span><br><span class="line">&lt;|im<span class="emphasis">_start|&gt;assistant</span></span><br></pre></td></tr></table></figure>

<h3 id="有Function的示例"><a href="#有Function的示例" class="headerlink" title="有Function的示例"></a>有Function的示例</h3><p>Qwen支持两种形式的Function定义格式，分别是Qwen格式和GPT格式，通常现在DeepSeek、Claude都是用的是GPT格式</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">gpt<span class="emphasis">_functions = [</span></span><br><span class="line"><span class="emphasis">    &#123;</span></span><br><span class="line"><span class="emphasis">        &quot;name&quot;: &quot;get_</span>current<span class="emphasis">_weather&quot;,</span></span><br><span class="line"><span class="emphasis">        &quot;description&quot;: &quot;Get the current weather in a given location.&quot;,</span></span><br><span class="line"><span class="emphasis">        &quot;parameters&quot;: &#123;</span></span><br><span class="line"><span class="emphasis">            &quot;type&quot;: &quot;object&quot;,</span></span><br><span class="line"><span class="emphasis">            &quot;properties&quot;: &#123;</span></span><br><span class="line"><span class="emphasis">                &quot;location&quot;: &#123;</span></span><br><span class="line"><span class="emphasis">                    &quot;type&quot;: &quot;string&quot;,</span></span><br><span class="line"><span class="emphasis">                    &quot;description&quot;: &quot;The city and state, e.g. San Francisco, CA&quot;,</span></span><br><span class="line"><span class="emphasis">                &#125;,</span></span><br><span class="line"><span class="emphasis">                &quot;unit&quot;: &#123;&quot;type&quot;: &quot;string&quot;, &quot;enum&quot;: [&quot;celsius&quot;, &quot;fahrenheit&quot;]&#125;,</span></span><br><span class="line"><span class="emphasis">            &#125;,</span></span><br><span class="line"><span class="emphasis">            &quot;required&quot;: [&quot;location&quot;],</span></span><br><span class="line"><span class="emphasis">        &#125;,</span></span><br><span class="line"><span class="emphasis">    &#125;</span></span><br><span class="line"><span class="emphasis">]</span></span><br></pre></td></tr></table></figure>

<p>通常现在服务并不会直接将Function的定义按照JSON Schema 直接原封不动的塞进Prompt或者Instruction中，而是按照固定格式将Function中的信息放到指定位置<br>如下所示是GPT风格的Prompt(ReAct的一种实现方式），对于Qwen的拼接，可以参考 <a target="_blank" rel="noopener" href="https://github.com/vllm-project/vllm/blob/main/examples/tool_chat_template_hermes.jinja">https://github.com/vllm-project/vllm/blob/main/examples/tool_chat_template_hermes.jinja</a></p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">GPT<span class="emphasis">_INSTRUCTION = &#x27;&#x27;&#x27;Answer the following questions as best you can. You have access to the following APIs:</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">get_</span>current<span class="emphasis">_weather: Call this tool to interact with the get_</span>current<span class="emphasis">_weather API. What is the get_</span>current<span class="emphasis">_weather API useful for? Get the current weather in a given location. Parameters: &#123;&quot;type&quot;: &quot;object&quot;, &quot;properties&quot;: &#123;&quot;location&quot;: &#123;&quot;type&quot;: &quot;string&quot;, &quot;description&quot;: &quot;The city and state, e.g. San Francisco, CA&quot;&#125;, &quot;unit&quot;: &#123;&quot;type&quot;: &quot;string&quot;, &quot;enum&quot;: [&quot;celsius&quot;, &quot;fahrenheit&quot;]&#125;&#125;, &quot;required&quot;: [&quot;location&quot;]&#125;</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">Use the following format:</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">Question: the input question you must answer</span></span><br><span class="line"><span class="emphasis">Thought: you should always think about what to do</span></span><br><span class="line"><span class="emphasis">Action: the action to take, should be one of [get_</span>current<span class="emphasis">_weather]</span></span><br><span class="line"><span class="emphasis">Action Input: the input to the action</span></span><br><span class="line"><span class="emphasis">Observation: the result of the action</span></span><br><span class="line"><span class="emphasis">... (this Thought/Action/Action Input/Observation can be repeated zero or more times)</span></span><br><span class="line"><span class="emphasis">Thought: I now know the final answer</span></span><br><span class="line"><span class="emphasis">Final Answer: the final answer to the original input question</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">Begin!&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<p>最后的输出结果就是（由于以上内容是在火山引擎上调用的DeepSeek-V3，应该有一层处理，使得我们没办法看到真实的output）<br>现在随着DeepSeeK-R1论文里提到的Function Call是伴随着Think后才产生的。现有的模型都会有Think的过程，然后才是<Tool_call> xxx<Tool_call></p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x27;<span class="language-xml"><span class="tag">&lt;<span class="name">think</span>&gt;</span></span>\n好的，用户问的是广州今天的天气如何。首先，我需要确定用户需要调用哪个工具。根据提供的工具列表，有一个get<span class="emphasis">_weather函数，需要location和time参数。用户提供的地点是广州，时间是今天。所以我要生成一个包含这两个参数的JSON对象。需要确认参数是否正确，location是字符串类型，time也是字符串类型，格式是YYYY-MM-DD。今天日期的话，假设当前是2023年10月5日，所以时间参数应该是&quot;2023-10-05&quot;。然后按照要求将函数名和参数放在tool_</span>call标签里。确保没有遗漏必填字段，这里两个参数都是必填的。检查格式是否正确，没有语法错误。最后返回结果。\n<span class="language-xml"><span class="tag">&lt;/<span class="name">think</span>&gt;</span></span>\n\n</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">tool_call</span>&gt;</span></span>\n&#123;&quot;location&quot;:&quot;广州&quot;&#125;\n<span class="language-xml">&lt;tool_call\&gt;</span></span><br></pre></td></tr></table></figure>

<p>不管是常规问答还是涉及 functions 的问答，训练和推断时都会对原本的 Question 及 Answer 进行对话模板的包装，实际输入模型进行训练和推断的文本不只有 System_Message、Question、Answer，还有身份标识符、换行符等其他字符。</p>
<p>但涉及 functions 的问答还有一点特殊的地方在于，所见并非所得。</p>
<p>模型推断时候的输出要么符合”Thought: xxx\nAction: xxx\nAction Input: xxx\nObservation: xxx\nThought: xxx\nFinal answer: xxx”形式，要么符合”Thought: xxx\nFinal answer: xxx”形式，不管是哪一种，调用者都只会看到部署代码处理后”Final answer: “之后的内容<br>训练时候同理，也需要将白话的 Answer 按既定模板要么包装成”Thought: xxx\nAction: xxx\nAction Input: xxx\nObservation: xxx\nThought: xxx\nFinal answer: xxx”形式，要么包装成”Thought: xxx\nFinal answer: xxx”形式，然后输入模型去学习指定格式<br>因此，虽然涉及 functions 的问答，对于调用者来说，所见并非所得；但对于模型来说，训练和推断时候其实是保持一致的。<br>因为模型本身并没有因为Function Call而有任何改变，只是在数据构造的时候新增了<Tool> &lt;Tool&gt; 这样的样式，让模型遇到这样的标识符时能够晓得，噢此时要工具调用了。</p>
<h3 id="Function-Call时SFT"><a href="#Function-Call时SFT" class="headerlink" title="Function-Call时SFT"></a>Function-Call时SFT</h3><p>以下给出一个Function Call的SFT时的数据，来源于 <a target="_blank" rel="noopener" href="https://github.com/bbruceyuan/LLMs-Zero-to-Hero/blob/master/Hands-on-Agents/video/function_call_infer_train.ipynb">https://github.com/bbruceyuan/LLMs-Zero-to-Hero/blob/master/Hands-on-Agents/video/function_call_infer_train.ipynb</a></p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;|im<span class="emphasis">_start|&gt;human</span></span><br><span class="line"><span class="emphasis">You are a function calling AI model. You are provided with function signatures within <span class="language-xml"><span class="tag">&lt;<span class="name">tools</span>&gt;</span></span><span class="language-xml"><span class="tag">&lt;/<span class="name">tools</span>&gt;</span></span> XML tags.You may call one or more functions to assist with the user query. Don&#x27;t make assumptions about what values to plug into functions.Here are the available tools:<span class="language-xml"><span class="tag">&lt;<span class="name">tools</span>&gt;</span></span> [&#123;&#x27;type&#x27;: &#x27;function&#x27;, &#x27;function&#x27;: &#123;&#x27;name&#x27;: &#x27;get_</span>news<span class="emphasis">_headlines&#x27;, &#x27;description&#x27;: &#x27;Get the latest news headlines&#x27;, &#x27;parameters&#x27;: &#123;&#x27;type&#x27;: &#x27;object&#x27;, &#x27;properties&#x27;: &#123;&#x27;country&#x27;: &#123;&#x27;type&#x27;: &#x27;string&#x27;, &#x27;description&#x27;: &#x27;The country for which headlines are needed&#x27;&#125;&#125;, &#x27;required&#x27;: [&#x27;country&#x27;]&#125;&#125;&#125;, &#123;&#x27;type&#x27;: &#x27;function&#x27;, &#x27;function&#x27;: &#123;&#x27;name&#x27;: &#x27;search_</span>recipes&#x27;, &#x27;description&#x27;: &#x27;Search for recipes based on ingredients&#x27;, &#x27;parameters&#x27;: &#123;&#x27;type&#x27;: &#x27;object&#x27;, &#x27;properties&#x27;: &#123;&#x27;ingredients&#x27;: &#123;&#x27;type&#x27;: &#x27;array&#x27;, &#x27;items&#x27;: &#123;&#x27;type&#x27;: &#x27;string&#x27;&#125;, &#x27;description&#x27;: &#x27;The list of ingredients&#x27;&#125;&#125;, &#x27;required&#x27;: [&#x27;ingredients&#x27;]&#125;&#125;&#125;] <span class="language-xml"><span class="tag">&lt;/<span class="name">tools</span>&gt;</span></span>Use the following pydantic model json schema for each tool call you will make: &#123;&#x27;title&#x27;: &#x27;FunctionCall&#x27;, &#x27;type&#x27;: &#x27;object&#x27;, &#x27;properties&#x27;: &#123;&#x27;arguments&#x27;: &#123;&#x27;title&#x27;: &#x27;Arguments&#x27;, &#x27;type&#x27;: &#x27;object&#x27;&#125;, &#x27;name&#x27;: &#123;&#x27;title&#x27;: &#x27;Name&#x27;, &#x27;type&#x27;: &#x27;string&#x27;&#125;&#125;, &#x27;required&#x27;: [&#x27;arguments&#x27;, &#x27;name&#x27;]&#125;For each function call return a json object with function name and arguments within <span class="language-xml"><span class="tag">&lt;<span class="name">tool_call</span>&gt;</span></span><span class="language-xml"><span class="tag">&lt;/<span class="name">tool_call</span>&gt;</span></span> XML tags as follows:</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">tool_call</span>&gt;</span></span></span><br><span class="line">&#123;tool<span class="emphasis">_call&#125;</span></span><br><span class="line"><span class="emphasis"><span class="language-xml"><span class="tag">&lt;/<span class="name">tool_call</span>&gt;</span></span>Also, before making a call to a function take the time to plan the function to take. Make that thinking process between <span class="language-xml"><span class="tag">&lt;<span class="name">think</span>&gt;</span></span>&#123;your thoughts&#125;<span class="language-xml"><span class="tag">&lt;/<span class="name">think</span>&gt;</span></span></span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">Can you get me the latest news headlines for the United States?&lt;|im_</span>end|&gt;</span><br><span class="line">&lt;|im<span class="emphasis">_start|&gt;model</span></span><br><span class="line"><span class="emphasis"><span class="language-xml"><span class="tag">&lt;<span class="name">think</span>&gt;</span></span>Okay, so the user asked for the latest news headlines in the United States. I need to figure out how to respond appropriately using the tools available.</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">Looking at the tools provided, there&#x27;s a function called get_</span>news<span class="emphasis">_headlines. That seems perfect for this situation. It requires a country code, which the user specified as the United States.</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">Since the user is asking specifically about the US, I&#x27;ll use the country parameter as &#x27;United States&#x27; in the function call. This should fetch the relevant news for them.</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">I should make sure to format the response correctly as a JSON object with the function name and arguments.</span></span><br><span class="line"><span class="emphasis"><span class="language-xml"><span class="tag">&lt;/<span class="name">think</span>&gt;</span></span><span class="language-xml"><span class="tag">&lt;<span class="name">tool_call</span>&gt;</span></span></span></span><br><span class="line"><span class="emphasis">&#123;&#x27;name&#x27;: &#x27;get_</span>news<span class="emphasis">_headlines&#x27;, &#x27;arguments&#x27;: &#123;&#x27;country&#x27;: &#x27;United States&#x27;&#125;&#125;</span></span><br><span class="line"><span class="emphasis"><span class="language-xml"><span class="tag">&lt;/<span class="name">tool_call</span>&gt;</span></span>&lt;|im_</span>end|&gt;</span><br><span class="line">&lt;|im<span class="emphasis">_start|&gt;tool</span></span><br><span class="line"><span class="emphasis"><span class="language-xml"><span class="tag">&lt;<span class="name">tool_response</span>&gt;</span></span></span></span><br><span class="line"><span class="emphasis">&#123;&#x27;headlines&#x27;: [&#x27;US President signs new bill into law&#x27;, &#x27;Major earthquake hits California&#x27;, &#x27;NASA announces new Mars mission&#x27;, &#x27;Tech giant releases new smartphone&#x27;, &#x27;US economy shows signs of recovery&#x27;]&#125;</span></span><br><span class="line"><span class="emphasis"><span class="language-xml"><span class="tag">&lt;/<span class="name">tool_response</span>&gt;</span></span>&lt;|im_</span>end|&gt;</span><br><span class="line">&lt;|im<span class="emphasis">_start|&gt;model</span></span><br><span class="line"><span class="emphasis">Here are the latest news headlines for the United States:</span></span><br><span class="line"><span class="emphasis">1. US President signs new bill into law</span></span><br><span class="line"><span class="emphasis">2. Major earthquake hits California</span></span><br><span class="line"><span class="emphasis">3. NASA announces new Mars mission</span></span><br><span class="line"><span class="emphasis">4. Tech giant releases new smartphone</span></span><br><span class="line"><span class="emphasis">5. US economy shows signs of recovery&lt;|im_</span>end|&gt;</span><br><span class="line">&lt;|im<span class="emphasis">_start|&gt;human</span></span><br><span class="line"><span class="emphasis">That&#x27;s interesting. Can you get me the news for France now?&lt;|im_</span>end|&gt;</span><br><span class="line">&lt;|im<span class="emphasis">_start|&gt;model</span></span><br><span class="line"><span class="emphasis"><span class="language-xml"><span class="tag">&lt;<span class="name">think</span>&gt;</span></span>Okay, the user initially asked for the latest US news, so I used get_</span>news<span class="emphasis">_headlines with &#x27;United States&#x27;. Now the user is asking for France, so I&#x27;ll call the same function with &#x27;France&#x27; as the country. That makes sense because the function is designed for any country.</span></span><br><span class="line"><span class="emphasis"><span class="language-xml"><span class="tag">&lt;/<span class="name">think</span>&gt;</span></span><span class="language-xml"><span class="tag">&lt;<span class="name">tool_call</span>&gt;</span></span></span></span><br><span class="line"><span class="emphasis">&#123;&#x27;name&#x27;: &#x27;get_</span>news<span class="emphasis">_headlines&#x27;, &#x27;arguments&#x27;: &#123;&#x27;country&#x27;: &#x27;France&#x27;&#125;&#125;</span></span><br><span class="line"><span class="emphasis"><span class="language-xml"><span class="tag">&lt;/<span class="name">tool_call</span>&gt;</span></span>&lt;|im_</span>end|&gt;</span><br><span class="line">&lt;|im<span class="emphasis">_start|&gt;tool</span></span><br><span class="line"><span class="emphasis"><span class="language-xml"><span class="tag">&lt;<span class="name">tool_response</span>&gt;</span></span></span></span><br><span class="line"><span class="emphasis">&#123;&#x27;headlines&#x27;: [&#x27;French President announces new environmental policy&#x27;, &#x27;Paris Fashion Week highlights&#x27;, &#x27;France wins World Cup qualifier&#x27;, &#x27;New culinary trend sweeps across France&#x27;, &#x27;French tech startup raises millions in funding&#x27;]&#125;</span></span><br><span class="line"><span class="emphasis"><span class="language-xml"><span class="tag">&lt;/<span class="name">tool_response</span>&gt;</span></span>&lt;|im_</span>end|&gt;</span><br><span class="line">&lt;|im<span class="emphasis">_start|&gt;model</span></span><br><span class="line"><span class="emphasis">Here are the latest news headlines for France:</span></span><br><span class="line"><span class="emphasis">1. French President announces new environmental policy</span></span><br><span class="line"><span class="emphasis">2. Paris Fashion Week highlights</span></span><br><span class="line"><span class="emphasis">3. France wins World Cup qualifier</span></span><br><span class="line"><span class="emphasis">4. New culinary trend sweeps across France</span></span><br><span class="line"><span class="emphasis">5. French tech startup raises millions in funding&lt;|im_</span>end|&gt;</span><br></pre></td></tr></table></figure>

<p>通过以上样例可以发现，&lt;|im_start|&gt;model xxx &lt;|im_end|&gt; 之间存在tool,那么说明tool的选择是需要计算loss，而loss的output（在React中叫observation）不需要计算loss，<br>而根据工具调用的结果继续生成的内容，同样需要计算Loss，因此总结一下，在以上内容中，需要计算Loss的部分为：</p>
<ol>
<li><think> … <think/> 中的部分</li>
<li><tool_call> … <tool_call> 中的部分</li>
<li>&lt;|im_start|&gt;model … &lt;|im_end|&gt; 中的部分</li>
</ol>
<p>因此构造SFT等数据时，需要针对这些部分进行严格筛选，确保数据的准确性。以上内容可参考（<a target="_blank" rel="noopener" href="https://github.com/QwenLM/Qwen-Agent/issues/112%EF%BC%89">https://github.com/QwenLM/Qwen-Agent/issues/112）</a></p>
<h2 id="利用VLLM部署Qwen实现Function-Call"><a href="#利用VLLM部署Qwen实现Function-Call" class="headerlink" title="利用VLLM部署Qwen实现Function Call"></a>利用VLLM部署Qwen实现Function Call</h2><p><a target="_blank" rel="noopener" href="https://docs.vllm.ai/en/stable/features/tool_calling.html#qwen-models">https://docs.vllm.ai/en/stable/features/tool_calling.html#qwen-models</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vllm serve /gz-data/Qwen/Qwen3-8B --gpu_memory_utilization 0.9 --max_model_len 4096 --enable-auto-tool-choice --tool-call-parser hermes</span><br></pre></td></tr></table></figure>


<h2 id="Function-Call常见的问题"><a href="#Function-Call常见的问题" class="headerlink" title="Function Call常见的问题"></a>Function Call常见的问题</h2><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/t8KDs9xtRF8nqiijfQoxFg">https://mp.weixin.qq.com/s/t8KDs9xtRF8nqiijfQoxFg</a><br><a target="_blank" rel="noopener" href="https://arxiv.org/html/2410.04587v2#bib.bib24">https://arxiv.org/html/2410.04587v2#bib.bib24</a><br>也有相关Benchmark dataset 和常见方法的介绍<br>以下两个问题可以参见这篇文章，这篇文章思路来源是工程实践，对于一些API调用等，作者建议可以使用RAG + FC Template的方式</p>
<ul>
<li>函数名称和参数名称的误导</li>
<li>过度关注命名的影响</li>
</ul>
<h2 id="Agent-Tool、Function-Call和MCP的关系"><a href="#Agent-Tool、Function-Call和MCP的关系" class="headerlink" title="Agent Tool、Function Call和MCP的关系"></a>Agent Tool、Function Call和MCP的关系</h2><p>以读取某个目录的文件这个任务为例</p>
<p>传统的AI Agent Tool方法很简单粗暴，我们会将可能用到的方法直接写入到System Prompt或者Instruction中去，如果我们想使用的话，就会让LLM直接返回调用的工具名和参数，<br>此时<strong>返回内容的格式等都是我们人为定义好的</strong>，由于LLM生成的随机性，返回的格式可能错误，此时例如Cline、Auto GPT等都是采用<strong>重试</strong>的方法来实现纠错的。</p>
<p>Function Calling的核心思想是统一格式，Tool、Function的有比较标准的定义，这些定义一般都是用JSON格式存储，并且定义内容一般不在System Prompt中。因此所有的Function、Tool<br>格式都是一致的，返回内容都是一致的。同时如果出错了，服务端其实可以在发送返回内容时进行检测，并进行重试，这样用户感知不到错误。但是这个仍然存在一些问题，<br>例如很多模型并不支持Function Calling，甚至不同的推理框架、训练方式都会导致Function calling出现差异。因为这受到模板等问题带来的差异。</p>
<p>MCP：通常AI Agent Tool和Function Calling是如何在AI和Tool之间进行通信的，这通常在同一个程序中进行调用的。因此长期以往会发现，大家对于某些需求用到的函数都是一致的，<br>例如浏览网页的Tool，获取天气的Tool的，为了避免重复定义这些Tool，这样不够优雅并且很冗余，因此可以把一些Tool变成统一的服务进行托管，让所有的Agent都来调用，<br>这就是MCP，MCP规定了MCP server和MCP Agent，MCP Server规定了有哪些通信规则、Tools、调用方法等，MCP Agent就负责执行需求。<br><img src="/images/MCP.png" alt="MCP基本流程"></p>
<h2 id="MCP详解"><a href="#MCP详解" class="headerlink" title="MCP详解"></a>MCP详解</h2><p>可以参考这篇文章 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/29001189476">https://zhuanlan.zhihu.com/p/29001189476</a></p>
<h3 id="MCP中模型是如何选择工具的"><a href="#MCP中模型是如何选择工具的" class="headerlink" title="MCP中模型是如何选择工具的"></a>MCP中模型是如何选择工具的</h3><p>这里以MCP官方提供的源码为讲解示例，可以发现<strong>模型是通过Prompt来确定有哪些工具可以调用的，通过将工具的具体使用描述以文本的形式<br>传给模型，让模型自己选择使用哪些工具</strong>，这个其实与传统的Function Calling是一致的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">start</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Main chat session handler.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">for</span> server <span class="keyword">in</span> <span class="variable language_">self</span>.servers:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    <span class="keyword">await</span> server.initialize()</span><br><span class="line">                <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                    logging.error(<span class="string">f&quot;Failed to initialize server: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">                    <span class="keyword">await</span> <span class="variable language_">self</span>.cleanup_servers()</span><br><span class="line">                    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">            all_tools = []</span><br><span class="line">            <span class="keyword">for</span> server <span class="keyword">in</span> <span class="variable language_">self</span>.servers:</span><br><span class="line">                tools = <span class="keyword">await</span> server.list_tools()</span><br><span class="line">                all_tools.extend(tools)</span><br><span class="line"></span><br><span class="line">            tools_description = <span class="string">&quot;\n&quot;</span>.join([tool.format_for_llm() <span class="keyword">for</span> tool <span class="keyword">in</span> all_tools])</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 这里是将所有Tool的描述写入到system_message中</span></span><br><span class="line">            system_message = (</span><br><span class="line">                <span class="string">&quot;You are a helpful assistant with access to these tools:\n\n&quot;</span></span><br><span class="line">                <span class="string">f&quot;<span class="subst">&#123;tools_description&#125;</span>\n&quot;</span></span><br><span class="line">                <span class="string">&quot;Choose the appropriate tool based on the user&#x27;s question. &quot;</span></span><br><span class="line">                <span class="string">&quot;If no tool is needed, reply directly.\n\n&quot;</span></span><br><span class="line">                <span class="string">&quot;IMPORTANT: When you need to use a tool, you must ONLY respond with &quot;</span></span><br><span class="line">                <span class="string">&quot;the exact JSON object format below, nothing else:\n&quot;</span></span><br><span class="line">                <span class="string">&quot;&#123;\n&quot;</span></span><br><span class="line">                <span class="string">&#x27;    &quot;tool&quot;: &quot;tool-name&quot;,\n&#x27;</span></span><br><span class="line">                <span class="string">&#x27;    &quot;arguments&quot;: &#123;\n&#x27;</span></span><br><span class="line">                <span class="string">&#x27;        &quot;argument-name&quot;: &quot;value&quot;\n&#x27;</span></span><br><span class="line">                <span class="string">&quot;    &#125;\n&quot;</span></span><br><span class="line">                <span class="string">&quot;&#125;\n\n&quot;</span></span><br><span class="line">                <span class="string">&quot;After receiving a tool&#x27;s response:\n&quot;</span></span><br><span class="line">                <span class="string">&quot;1. Transform the raw data into a natural, conversational response\n&quot;</span></span><br><span class="line">                <span class="string">&quot;2. Keep responses concise but informative\n&quot;</span></span><br><span class="line">                <span class="string">&quot;3. Focus on the most relevant information\n&quot;</span></span><br><span class="line">                <span class="string">&quot;4. Use appropriate context from the user&#x27;s question\n&quot;</span></span><br><span class="line">                <span class="string">&quot;5. Avoid simply repeating the raw data\n\n&quot;</span></span><br><span class="line">                <span class="string">&quot;Please use only the tools that are explicitly defined above.&quot;</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            messages = [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: system_message&#125;]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    user_input = <span class="built_in">input</span>(<span class="string">&quot;You: &quot;</span>).strip().lower()</span><br><span class="line">                    <span class="keyword">if</span> user_input <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>]:</span><br><span class="line">                        logging.info(<span class="string">&quot;\nExiting...&quot;</span>)</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">                    messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_input&#125;)</span><br><span class="line"></span><br><span class="line">                    llm_response = <span class="variable language_">self</span>.llm_client.get_response(messages)</span><br><span class="line">                    logging.info(<span class="string">&quot;\nAssistant: %s&quot;</span>, llm_response)</span><br><span class="line"></span><br><span class="line">                    result = <span class="keyword">await</span> <span class="variable language_">self</span>.process_llm_response(llm_response)</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> result != llm_response:</span><br><span class="line">                        messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: llm_response&#125;)</span><br><span class="line">                        messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: result&#125;)</span><br><span class="line"></span><br><span class="line">                        final_response = <span class="variable language_">self</span>.llm_client.get_response(messages)</span><br><span class="line">                        logging.info(<span class="string">&quot;\nFinal response: %s&quot;</span>, final_response)</span><br><span class="line">                        messages.append(</span><br><span class="line">                            &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: final_response&#125;</span><br><span class="line">                        )</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: llm_response&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">                    logging.info(<span class="string">&quot;\nExiting...&quot;</span>)</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">finally</span>:</span><br><span class="line">            <span class="keyword">await</span> <span class="variable language_">self</span>.cleanup_servers()</span><br></pre></td></tr></table></figure>


<p>MCP官方对于Tool的定义以及如何转换为文本如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Tool</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Represents a tool with its properties and formatting.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self, name: <span class="built_in">str</span>, description: <span class="built_in">str</span>, input_schema: <span class="built_in">dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>]</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="variable language_">self</span>.name: <span class="built_in">str</span> = name</span><br><span class="line">        <span class="variable language_">self</span>.description: <span class="built_in">str</span> = description</span><br><span class="line">        <span class="variable language_">self</span>.input_schema: <span class="built_in">dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>] = input_schema</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 这里将工具的名称、用途以及所需要的参数都会转为文本</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">format_for_llm</span>(<span class="params">self</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Format tool information for LLM.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            A formatted string describing the tool.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        args_desc = []</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;properties&quot;</span> <span class="keyword">in</span> <span class="variable language_">self</span>.input_schema:</span><br><span class="line">            <span class="keyword">for</span> param_name, param_info <span class="keyword">in</span> <span class="variable language_">self</span>.input_schema[<span class="string">&quot;properties&quot;</span>].items():</span><br><span class="line">                arg_desc = (</span><br><span class="line">                    <span class="string">f&quot;- <span class="subst">&#123;param_name&#125;</span>: <span class="subst">&#123;param_info.get(<span class="string">&#x27;description&#x27;</span>, <span class="string">&#x27;No description&#x27;</span>)&#125;</span>&quot;</span></span><br><span class="line">                )</span><br><span class="line">                <span class="keyword">if</span> param_name <span class="keyword">in</span> <span class="variable language_">self</span>.input_schema.get(<span class="string">&quot;required&quot;</span>, []):</span><br><span class="line">                    arg_desc += <span class="string">&quot; (required)&quot;</span></span><br><span class="line">                args_desc.append(arg_desc)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Tool: <span class="subst">&#123;self.name&#125;</span></span></span><br><span class="line"><span class="string">Description: <span class="subst">&#123;self.description&#125;</span></span></span><br><span class="line"><span class="string">Arguments:</span></span><br><span class="line"><span class="string"><span class="subst">&#123;<span class="built_in">chr</span>(<span class="number">10</span>).join(args_desc)&#125;</span></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>大部分情况下，当使用装饰器 @mcp.tool() 来装饰函数时，对应的 name 和 description 等其实直接源自用户定义函数的函数名以及函数的 docstring 等。<br>  <a target="_blank" rel="noopener" href="https://github.com/modelcontextprotocol/python-sdk/blob/main/src/mcp/server/fastmcp/tools/base.py">https://github.com/modelcontextprotocol/python-sdk/blob/main/src/mcp/server/fastmcp/tools/base.py</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@classmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">from_function</span>(<span class="params"></span></span><br><span class="line"><span class="params">    cls,</span></span><br><span class="line"><span class="params">    fn: <span class="type">Callable</span>,</span></span><br><span class="line"><span class="params">    name: <span class="built_in">str</span> | <span class="literal">None</span> = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    description: <span class="built_in">str</span> | <span class="literal">None</span> = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    context_kwarg: <span class="built_in">str</span> | <span class="literal">None</span> = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="string">&quot;Tool&quot;</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Create a Tool from a function.&quot;&quot;&quot;</span></span><br><span class="line">    func_name = name <span class="keyword">or</span> fn.__name__ <span class="comment"># 获取函数名</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> func_name == <span class="string">&quot;&lt;lambda&gt;&quot;</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;You must provide a name for lambda functions&quot;</span>)</span><br><span class="line"></span><br><span class="line">    func_doc = description <span class="keyword">or</span> fn.__doc__ <span class="keyword">or</span> <span class="string">&quot;&quot;</span> <span class="comment"># 获取函数 docstring</span></span><br><span class="line">    is_async = inspect.iscoroutinefunction(fn)</span><br></pre></td></tr></table></figure>
<p>总结来说，LLM还是通过Prompt Engineering来实现，即提供所有工具的结构化描述和few-shot的example来介绍应该怎么使用工具，<br>当然在这里如果需要提升MCP的能力，肯定是<strong>需要对LLM进行微调，使得LLM能够更好地使用工具以及结构化输出</strong></p>
<h3 id="MCP是如何使用工具的"><a href="#MCP是如何使用工具的" class="headerlink" title="MCP是如何使用工具的"></a>MCP是如何使用工具的</h3><p>这一步也是类似Function Calling的，将含有工具描述信息的System Prompt和用户信息一起发送给模型，让模型自己来决定是否要实用工具。<br>如果模型执行了 tool call，则工具执行的结果 result 会和 system prompt 和用户消息一起重新发送给模型，请求模型生成最终回复。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">  <span class="keyword">try</span>:</span><br><span class="line">      user_input = <span class="built_in">input</span>(<span class="string">&quot;You: &quot;</span>).strip().lower()</span><br><span class="line">      <span class="keyword">if</span> user_input <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>]:</span><br><span class="line">          logging.info(<span class="string">&quot;\nExiting...&quot;</span>)</span><br><span class="line">          <span class="keyword">break</span></span><br><span class="line">  </span><br><span class="line">      messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_input&#125;)</span><br><span class="line">  </span><br><span class="line">      llm_response = <span class="variable language_">self</span>.llm_client.get_response(messages)</span><br><span class="line">      logging.info(<span class="string">&quot;\nAssistant: %s&quot;</span>, llm_response)</span><br><span class="line">  </span><br><span class="line">      result = <span class="keyword">await</span> <span class="variable language_">self</span>.process_llm_response(llm_response)</span><br><span class="line">  </span><br><span class="line">      <span class="keyword">if</span> result != llm_response:</span><br><span class="line">          messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: llm_response&#125;)</span><br><span class="line">          messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: result&#125;)</span><br><span class="line">  </span><br><span class="line">          final_response = <span class="variable language_">self</span>.llm_client.get_response(messages)</span><br><span class="line">          logging.info(<span class="string">&quot;\nFinal response: %s&quot;</span>, final_response)</span><br><span class="line">          messages.append(</span><br><span class="line">              &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: final_response&#125;</span><br><span class="line">          )</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">          messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: llm_response&#125;)</span><br></pre></td></tr></table></figure>

<p>下面是服务端实接收到LLM调用工具的请求时，作出的反应，如果需要调用工具，那么会等待server.execute_tool调用工具的返回结果，<br>否则直接返回请求，即用自然语言。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">  tool_call = json.loads(llm_response)</span><br><span class="line">  <span class="keyword">if</span> <span class="string">&quot;tool&quot;</span> <span class="keyword">in</span> tool_call <span class="keyword">and</span> <span class="string">&quot;arguments&quot;</span> <span class="keyword">in</span> tool_call:</span><br><span class="line">      logging.info(<span class="string">f&quot;Executing tool: <span class="subst">&#123;tool_call[<span class="string">&#x27;tool&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line">      logging.info(<span class="string">f&quot;With arguments: <span class="subst">&#123;tool_call[<span class="string">&#x27;arguments&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line">  </span><br><span class="line">      <span class="keyword">for</span> server <span class="keyword">in</span> <span class="variable language_">self</span>.servers:</span><br><span class="line">          tools = <span class="keyword">await</span> server.list_tools()</span><br><span class="line">          <span class="keyword">if</span> <span class="built_in">any</span>(tool.name == tool_call[<span class="string">&quot;tool&quot;</span>] <span class="keyword">for</span> tool <span class="keyword">in</span> tools):</span><br><span class="line">              <span class="keyword">try</span>:</span><br><span class="line">                  result = <span class="keyword">await</span> server.execute_tool(</span><br><span class="line">                      tool_call[<span class="string">&quot;tool&quot;</span>], tool_call[<span class="string">&quot;arguments&quot;</span>]</span><br><span class="line">                  )</span><br><span class="line">  </span><br><span class="line">                  <span class="keyword">if</span> <span class="built_in">isinstance</span>(result, <span class="built_in">dict</span>) <span class="keyword">and</span> <span class="string">&quot;progress&quot;</span> <span class="keyword">in</span> result:</span><br><span class="line">                      progress = result[<span class="string">&quot;progress&quot;</span>]</span><br><span class="line">                      total = result[<span class="string">&quot;total&quot;</span>]</span><br><span class="line">                      percentage = (progress / total) * <span class="number">100</span></span><br><span class="line">                      logging.info(</span><br><span class="line">                          <span class="string">f&quot;Progress: <span class="subst">&#123;progress&#125;</span>/<span class="subst">&#123;total&#125;</span> (<span class="subst">&#123;percentage:<span class="number">.1</span>f&#125;</span>%)&quot;</span></span><br><span class="line">                      )</span><br><span class="line">  </span><br><span class="line">                  <span class="keyword">return</span> <span class="string">f&quot;Tool execution result: <span class="subst">&#123;result&#125;</span>&quot;</span></span><br><span class="line">              <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                  error_msg = <span class="string">f&quot;Error executing tool: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span></span><br><span class="line">                  logging.error(error_msg)</span><br><span class="line">                  <span class="keyword">return</span> error_msg</span><br><span class="line">  </span><br><span class="line">      <span class="keyword">return</span> <span class="string">f&quot;No server found with tool: <span class="subst">&#123;tool_call[<span class="string">&#x27;tool&#x27;</span>]&#125;</span>&quot;</span></span><br><span class="line">  <span class="keyword">return</span> llm_response</span><br></pre></td></tr></table></figure>
<p>结合以上内容可以总结得出：<br>工具文档至关重要 </p>
<ul>
<li>模型通过工具描述文本来理解和选择工具，因此精心编写工具的名称、docstring 和参数说明至关重要。<br>由于 MCP 的选择是基于 prompt 的，所以任何模型其实都适配 MCP，只要你能提供对应的工具描述。但是当你使用非 Claude 模型时，MCP 使用的效果和体验难以保证（没有做专门的训练）。</li>
</ul>
<h3 id="MCP相关文章"><a href="#MCP相关文章" class="headerlink" title="MCP相关文章"></a>MCP相关文章</h3><h4 id="MCP-RAG"><a href="#MCP-RAG" class="headerlink" title="MCP-RAG"></a>MCP-RAG</h4><p>RAG-MCP: Mitigating Prompt Bloat in LLM Tool Selection via Retrieval-Augmented Generation<br><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.03275">https://papers.cool/arxiv/2505.03275</a><br>论文试图解决大型语言模型（LLMs）在使用大量外部工具时面临的“提示膨胀（prompt bloat）”和选择复杂性问题。随着工具数量的增加，例如由模型上下文协议（Model Context Protocol, MCP）定义的工具，将所有工具的定义或使用说明都包含在模型的上下文中会导致上下文窗口被大量无关信息占据，从而降低模型区分和回忆正确工具的能力。此外，过多的工具选择会使模型在决定是否调用以及调用哪个工具时面临更复杂的决策过程，增加错误选择或误解工具功能的风险。 为了解决这些问题，论文提出了RAG-MCP框架，该框架通过检索增强生成（Retrieval-Augmented Generation, RAG）来动态检索与用户查询最相关的工具子集，而不是一次性将所有工具呈现给语言模型，从而减少上下文长度和复杂性，提高模型的决策能力。</p>
<h2 id="如何在垂直领域微调一个Function-Calling-或者MCP"><a href="#如何在垂直领域微调一个Function-Calling-或者MCP" class="headerlink" title="如何在垂直领域微调一个Function Calling 或者MCP"></a>如何在垂直领域微调一个Function Calling 或者MCP</h2><p>之前遇到的业务场景是，有几百个内部的API，需求是用户输入需求，LLM能够自动填充参数并且编排API调用；此时遇到的问题是几百个API无法一次性写入Prompt中，<br>此时我们考虑能否通过注入知识的方式让LLM学会我们的API，因为我们的API一般不会出现变动，造了一批数据大概几千条，每一个API至少有10个不同的输入输出，<br>通过SFT的方式进行学习，但是不幸的是，通过SFT无法有效注入知识，即容易产生幻觉，准确率不足5%，如果是写到Prompt里，准确率有个30%左右，因此效果并不好。<br>现在回忆起来应该方法不对，<strong>SFT通常无法注入这类新知识</strong>，需要在CPT、PT阶段注入，然后继续SFT，此时SFT最好有一个固定的System Prompt，用于区分和Base模型可能交叉的指令。<br>这么做的目的是能让LLM具备我们已知的API知识，并且需要保证输出完全正确、无幻觉。</p>
<p>Tool 描述太多也曾经尝试过用RAG去解决，是有提升，不过涉及到的工作流过于复杂，无法满足时效性。</p>
<p>曾经面试的时候和百度那边聊到过这种场景，他们也是用PT+SFT的方式，直接让LLM输出要使用的Tool、或者Id等，因为只专注某个非常细的任务，因此小模型可以胜任，<br>但是对于复杂调用的API，如嵌套、多个参数等的，可能小模型比较受限。总的来说，无论是FC还是MCP，如果需要微调一个领域内的，问题无非就是Tool Description过长<br>导致LLM性能下降、LLM逻辑能力不够导致选取函数和参数时受限，这其实可以通过PT新增我们用到的Tool的相关知识+SFT调用样本，这样可以在用户输入需求后，LLM直接<br>输出使用的Tool等，供下游调用。</p>
<p>这里缺少点文章，有空补上。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">QianLi Yang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://yangqianli92.github.io/">https://yangqianli92.github.io/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">QianLi Yang</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/LLM/">LLM</a></div><div class="post-share"><div class="social-share" data-image="/images/head.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/06/03/MCP-RAG/" title="LLM论文阅读:RAG-MCP：通过检索增强生成技术缓解大型语言模型工具选择中的提示膨胀问题"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">LLM论文阅读:RAG-MCP：通过检索增强生成技术缓解大型语言模型工具选择中的提示膨胀问题</div></div><div class="info-2"><div class="info-item-1">RAG-MCP: Mitigating Prompt Bloat in LLM Tool Selection via Retrieval-Augmented Generation [PDF5] [Copy] [Kimi19] [REL]Authors: Tiantian Gan, Qiyao Sun Large language models (LLMs) struggle to effectively utilize a growing number of external tools, such as those defined by the Model Context Protocol (MCP)\cite{IntroducingMCP}, due to prompt bloat and selection complexity. We introduce RAG-MCP, a Retrieval-Augmented Generation framework that overcomes this challenge by offloading tool...</div></div></div></a><a class="pagination-related" href="/2025/05/13/langrensha/" title="LLM实践:基于LLM的狼人杀文字版游戏"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">LLM实践:基于LLM的狼人杀文字版游戏</div></div><div class="info-2"><div class="info-item-1">游戏流程详细介绍整个狼人杀游戏的流程主要由 GameManager 类和 RoleAIManager 类协同完成，以下是详细的游戏流程： 1. 游戏初始化GameManager 初始化：在 GameManager 类的 __init__ 方法中，设置游戏的基本信息，如游戏 ID、轮次、日夜状态、玩家角色配置、存活玩家列表、死亡玩家记录等。角色分配：调用 startup 方法，随机分配玩家角色，并为每个玩家创建对应的 RoleAIManager 对象。同时，记录每个角色对应的玩家编号，以及每个玩家的真实角色。 2. 夜晚阶段狼人行动：在 act_at_night 方法中，首先处理狼人杀人。存活的狼人玩家通过 RoleAIManager 的 act_at_night 方法进行思考和投票，选择要杀的玩家。最后，随机选取一个得票最多的玩家作为被杀对象。预言家行动：存活的预言家玩家通过 RoleAIManager 的 act_at_night 方法进行思考和查看，选择要查验的玩家，并得知其身份。女巫行动：存活的女巫玩家根据狼人杀人情况，通过 RoleAIManager 的...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/06/10/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A02/" title="LLM论文阅读-狼人杀系列 探索LLM在社交类游戏的应用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-10</div><div class="info-item-2">LLM论文阅读-狼人杀系列 探索LLM在社交类游戏的应用</div></div><div class="info-2"><div class="info-item-1">Exploring Large Language Models for Communication Games: An Empirical Study on Werewolf  Authors: Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang, Weidong Liu, Yang Liu Communication games, which we refer to as incomplete information games that heavily depend on natural language communication, hold significant research value in fields such as economics, social science, and artificial intelligence. In this work, we explore the problem of how to engage large language models (LLMs) in...</div></div></div></a><a class="pagination-related" href="/2025/06/03/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A01/" title="LLM论文阅读-狼人杀系列 强化学习智能体在狼人杀中的策略玩法"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-03</div><div class="info-item-2">LLM论文阅读-狼人杀系列 强化学习智能体在狼人杀中的策略玩法</div></div><div class="info-2"><div class="info-item-1">#1 Language Agents with Reinforcement Learning for Strategic Play in the Werewolf GameAuthors: Zelai Xu, Chao Yu, Fei Fang, Yu Wang, Yi Wu Agents built with large language models (LLMs) have shown great potential across a wide range of domains. However, in complex decision-making tasks, pure LLM-based agents tend to exhibit intrinsic bias in their choice of actions, which is inherited from the model’s training data and results in suboptimal performance. To develop strategic language agents,...</div></div></div></a><a class="pagination-related" href="/2025/06/16/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A04/" title="LLM论文阅读-狼人杀系列4 利用多智能体强化学习训练社交推理语言模型"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-16</div><div class="info-item-2">LLM论文阅读-狼人杀系列4 利用多智能体强化学习训练社交推理语言模型</div></div><div class="info-2"><div class="info-item-1">Training Language Models for Social Deduction with Multi-Agent Reinforcement LearningAuthors: Bidipta Sarkar, Warren Xia, C. Karen Liu, Dorsa Sadigh Communicating in natural language is a powerful tool in multi-agent settings, as it enables independent agents to share information in partially observable settings and allows zero-shot coordination with humans. However, most prior works are limited as they either rely on training with large amounts of human demonstrations or lack the ability to...</div></div></div></a><a class="pagination-related" href="/2025/06/12/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A03/" title="LLM论文阅读-狼人杀系列 Werewolf 一个直观的游戏框架，配备文本转语音功能以提升用户参与度"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-12</div><div class="info-item-2">LLM论文阅读-狼人杀系列 Werewolf 一个直观的游戏框架，配备文本转语音功能以提升用户参与度</div></div><div class="info-2"><div class="info-item-1">Werewolf: A Straightforward Game Framework with TTS for Improved User Engagement  Authors: Qihui Fan, Enfu Nan, Wenbo Li, Lei Lu, Pu Zhao, Yanzhi Wang The growing popularity of social deduction game systems for both business applications and AI research has greatly benefited from the rapid advancements in Large Language Models (LLMs), which now demonstrate stronger reasoning and persuasion capabilities. Especially with the raise of DeepSeek R1 and V3 models, LLMs should enable a more...</div></div></div></a><a class="pagination-related" href="/2025/06/16/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A05/" title="LLM论文阅读-狼人杀系列5 Werewolf Arena"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-16</div><div class="info-item-2">LLM论文阅读-狼人杀系列5 Werewolf Arena</div></div><div class="info-2"><div class="info-item-1">Werewolf Arena: A Case Study in LLM Evaluation via Social Deduction Authors: Suma Bailis, Jane Friedhoff, Feiyang Chen This paper introduces Werewolf Arena, a novel framework for evaluating large language models (LLMs) through the lens of the classic social deduction game, Werewolf. In Werewolf Arena, LLMs compete against each other, navigating the game’s complex dynamics of deception, deduction, and persuasion. The framework introduces a dynamic turn-taking system based on bidding,...</div></div></div></a><a class="pagination-related" href="/2025/05/13/langrensha/" title="LLM实践:基于LLM的狼人杀文字版游戏"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-13</div><div class="info-item-2">LLM实践:基于LLM的狼人杀文字版游戏</div></div><div class="info-2"><div class="info-item-1">游戏流程详细介绍整个狼人杀游戏的流程主要由 GameManager 类和 RoleAIManager 类协同完成，以下是详细的游戏流程： 1. 游戏初始化GameManager 初始化：在 GameManager 类的 __init__ 方法中，设置游戏的基本信息，如游戏 ID、轮次、日夜状态、玩家角色配置、存活玩家列表、死亡玩家记录等。角色分配：调用 startup 方法，随机分配玩家角色，并为每个玩家创建对应的 RoleAIManager 对象。同时，记录每个角色对应的玩家编号，以及每个玩家的真实角色。 2. 夜晚阶段狼人行动：在 act_at_night 方法中，首先处理狼人杀人。存活的狼人玩家通过 RoleAIManager 的 act_at_night 方法进行思考和投票，选择要杀的玩家。最后，随机选取一个得票最多的玩家作为被杀对象。预言家行动：存活的预言家玩家通过 RoleAIManager 的 act_at_night 方法进行思考和查看，选择要查验的玩家，并得知其身份。女巫行动：存活的女巫玩家根据狼人杀人情况，通过 RoleAIManager 的...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/images/head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">QianLi Yang</div><div class="author-info-description">不定时更新程序员成长之路~</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">17</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/YangQianli92" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:chainllie92@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/Serein_Young" target="_blank" title="Wechat"><i class="fab fa-weixin"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Function-Calling"><span class="toc-number">1.</span> <span class="toc-text">Function Calling</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B7%A5%E5%85%B7%E8%B0%83%E7%94%A8%E7%A4%BA%E4%BE%8B"><span class="toc-number">1.1.</span> <span class="toc-text">工具调用示例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Function-calling%E6%95%B0%E6%8D%AE"><span class="toc-number">1.2.</span> <span class="toc-text">Function-calling数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A0Function%E7%9A%84%E7%A4%BA%E4%BE%8B"><span class="toc-number">1.2.1.</span> <span class="toc-text">无Function的示例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%89Function%E7%9A%84%E7%A4%BA%E4%BE%8B"><span class="toc-number">1.2.2.</span> <span class="toc-text">有Function的示例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Function-Call%E6%97%B6SFT"><span class="toc-number">1.2.3.</span> <span class="toc-text">Function-Call时SFT</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%A9%E7%94%A8VLLM%E9%83%A8%E7%BD%B2Qwen%E5%AE%9E%E7%8E%B0Function-Call"><span class="toc-number">1.3.</span> <span class="toc-text">利用VLLM部署Qwen实现Function Call</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Function-Call%E5%B8%B8%E8%A7%81%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">1.4.</span> <span class="toc-text">Function Call常见的问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Agent-Tool%E3%80%81Function-Call%E5%92%8CMCP%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">1.5.</span> <span class="toc-text">Agent Tool、Function Call和MCP的关系</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MCP%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.6.</span> <span class="toc-text">MCP详解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#MCP%E4%B8%AD%E6%A8%A1%E5%9E%8B%E6%98%AF%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%B7%A5%E5%85%B7%E7%9A%84"><span class="toc-number">1.6.1.</span> <span class="toc-text">MCP中模型是如何选择工具的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MCP%E6%98%AF%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E5%B7%A5%E5%85%B7%E7%9A%84"><span class="toc-number">1.6.2.</span> <span class="toc-text">MCP是如何使用工具的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MCP%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0"><span class="toc-number">1.6.3.</span> <span class="toc-text">MCP相关文章</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#MCP-RAG"><span class="toc-number">1.6.3.1.</span> <span class="toc-text">MCP-RAG</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%9C%A8%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AAFunction-Calling-%E6%88%96%E8%80%85MCP"><span class="toc-number">1.7.</span> <span class="toc-text">如何在垂直领域微调一个Function Calling 或者MCP</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/18/%E6%A2%A6%E5%B9%BB%E8%A5%BF%E6%B8%B8%E4%BD%93%E9%AA%8C%E6%8A%A5%E5%91%8A/" title="无标题">无标题</a><time datetime="2025-06-18T13:53:18.873Z" title="发表于 2025-06-18 21:53:18">2025-06-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/18/%E6%A2%A6%E5%B9%BB%E8%A5%BF%E6%B8%B8/" title="AI赋能《梦幻西游手游》内挂：利用大语言模型与智能体实现玩家托管自动化">AI赋能《梦幻西游手游》内挂：利用大语言模型与智能体实现玩家托管自动化</a><time datetime="2025-06-18T12:44:48.000Z" title="发表于 2025-06-18 20:44:48">2025-06-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/16/%E7%8B%BC%E4%BA%BA%E6%9D%80/" title="基于大语言模型（LLM）驱动的AI狼人杀综述">基于大语言模型（LLM）驱动的AI狼人杀综述</a><time datetime="2025-06-16T09:31:08.000Z" title="发表于 2025-06-16 17:31:08">2025-06-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/16/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A04/" title="LLM论文阅读-狼人杀系列4 利用多智能体强化学习训练社交推理语言模型">LLM论文阅读-狼人杀系列4 利用多智能体强化学习训练社交推理语言模型</a><time datetime="2025-06-16T04:46:48.000Z" title="发表于 2025-06-16 12:46:48">2025-06-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/16/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A05/" title="LLM论文阅读-狼人杀系列5 Werewolf Arena">LLM论文阅读-狼人杀系列5 Werewolf Arena</a><time datetime="2025-06-16T04:46:48.000Z" title="发表于 2025-06-16 12:46:48">2025-06-16</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By QianLi Yang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>