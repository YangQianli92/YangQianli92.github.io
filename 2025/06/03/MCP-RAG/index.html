<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>LLM论文阅读:RAG-MCP：通过检索增强生成技术缓解大型语言模型工具选择中的提示膨胀问题 | QianLi Yang</title><meta name="author" content="QianLi Yang"><meta name="copyright" content="QianLi Yang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="RAG-MCP: Mitigating Prompt Bloat in LLM Tool Selection via Retrieval-Augmented Generation [PDF5] [Copy] [Kimi19] [REL]Authors: Tiantian Gan, Qiyao Sun Large language models (LLMs) struggle to effectiv">
<meta property="og:type" content="article">
<meta property="og:title" content="LLM论文阅读:RAG-MCP：通过检索增强生成技术缓解大型语言模型工具选择中的提示膨胀问题">
<meta property="og:url" content="http://example.com/2025/06/03/MCP-RAG/index.html">
<meta property="og:site_name" content="QianLi Yang">
<meta property="og:description" content="RAG-MCP: Mitigating Prompt Bloat in LLM Tool Selection via Retrieval-Augmented Generation [PDF5] [Copy] [Kimi19] [REL]Authors: Tiantian Gan, Qiyao Sun Large language models (LLMs) struggle to effectiv">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/images/head.jpg">
<meta property="article:published_time" content="2025-06-03T04:46:48.000Z">
<meta property="article:modified_time" content="2025-06-03T05:16:10.150Z">
<meta property="article:author" content="QianLi Yang">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="Paper">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/head.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2025/06/03/MCP-RAG/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'LLM论文阅读:RAG-MCP：通过检索增强生成技术缓解大型语言模型工具选择中的提示膨胀问题',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/images/head.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">16</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://github.com/YangQianli92"><i class="fa-fw fab fa-github"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">QianLi Yang</span></a><a class="nav-page-title" href="/"><span class="site-name">LLM论文阅读:RAG-MCP：通过检索增强生成技术缓解大型语言模型工具选择中的提示膨胀问题</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://github.com/YangQianli92"><i class="fa-fw fab fa-github"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">LLM论文阅读:RAG-MCP：通过检索增强生成技术缓解大型语言模型工具选择中的提示膨胀问题</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-06-03T04:46:48.000Z" title="发表于 2025-06-03 12:46:48">2025-06-03</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-06-03T05:16:10.150Z" title="更新于 2025-06-03 13:16:10">2025-06-03</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="RAG-MCP-Mitigating-Prompt-Bloat-in-LLM-Tool-Selection-via-Retrieval-Augmented-Generation-PDF5-Copy-Kimi19-REL"><a href="#RAG-MCP-Mitigating-Prompt-Bloat-in-LLM-Tool-Selection-via-Retrieval-Augmented-Generation-PDF5-Copy-Kimi19-REL" class="headerlink" title="RAG-MCP: Mitigating Prompt Bloat in LLM Tool Selection via Retrieval-Augmented Generation [PDF5] [Copy] [Kimi19] [REL]"></a>RAG-MCP: Mitigating Prompt Bloat in LLM Tool Selection via Retrieval-Augmented Generation [PDF5] [Copy] [Kimi19] [REL]</h2><p>Authors: Tiantian Gan, Qiyao Sun</p>
<p>Large language models (LLMs) struggle to effectively utilize a growing number of external tools, such as those defined by the Model Context Protocol (MCP)\cite{IntroducingMCP}, due to prompt bloat and selection complexity. We introduce RAG-MCP, a Retrieval-Augmented Generation framework that overcomes this challenge by offloading tool discovery. RAG-MCP uses semantic retrieval to identify the most relevant MCP(s) for a given query from an external index before engaging the LLM. Only the selected tool descriptions are passed to the model, drastically reducing prompt size and simplifying decision-making. Experiments, including an MCP stress test, demonstrate RAG-MCP significantly cuts prompt tokens (e.g., by over 50%) and more than triples tool selection accuracy (43.13% vs 13.62% baseline) on benchmark tasks. RAG-MCP enables scalable and accurate tool integration for LLMs.</p>
<p>Subjects: Artificial Intelligence, Software Engineering</p>
<p>Publish: 2025-05-06 08:05:35 UTC</p>
<p><strong>Q</strong>: 这篇论文试图解决什么问题？</p>
<p><strong>A</strong>: 这篇论文试图解决大型语言模型（LLMs）在使用大量外部工具时面临的“提示膨胀（prompt bloat）”和选择复杂性问题。随着工具数量的增加，例如由模型上下文协议（Model Context Protocol, MCP）定义的工具，将所有工具的定义或使用说明都包含在模型的上下文中会导致上下文窗口被大量无关信息占据，从而降低模型区分和回忆正确工具的能力。此外，过多的工具选择会使模型在决定是否调用以及调用哪个工具时面临更复杂的决策过程，增加错误选择或误解工具功能的风险。 为了解决这些问题，论文提出了RAG-MCP框架，该框架通过检索增强生成（Retrieval-Augmented Generation, RAG）来动态检索与用户查询最相关的工具子集，而不是一次性将所有工具呈现给语言模型，从而减少上下文长度和复杂性，提高模型的决策能力。</p>
<p><strong>Q</strong>: 有哪些相关研究？</p>
<p><strong>A</strong>: 论文中提到了以下相关研究：</p>
<h3 id="工具使用在LLMs中的研究"><a href="#工具使用在LLMs中的研究" class="headerlink" title="工具使用在LLMs中的研究"></a>工具使用在LLMs中的研究</h3><ul>
<li><strong>Toolformer</strong>：通过自监督学习，让模型学会何时以及如何调用API（如计算器或搜索引擎），从而提高跨任务的零样本性能。</li>
<li><strong>ReAct</strong>：将推理步骤与行动步骤交织在一起，使LLM能够与外部环境（例如维基百科API）进行交互，从而产生更易于解释且更准确的多步骤解决方案。</li>
<li><strong>WebGPT</strong>：在模拟的浏览器环境中对GPT-3进行微调，训练其进行导航、搜索和引用来源，以减少幻觉并提高长篇问答的准确性。</li>
<li><strong>ChatGPT Plugins</strong>：引入了一个生产级的插件生态系统，允许ChatGPT访问最新信息和第三方服务，同时确保安全性和可控性。</li>
</ul>
<h3 id="检索增强生成（RAG）的研究"><a href="#检索增强生成（RAG）的研究" class="headerlink" title="检索增强生成（RAG）的研究"></a>检索增强生成（RAG）的研究</h3><ul>
<li><strong>RAG</strong>：首次将参数化LLM与非参数化记忆（密集向量索引）结合起来，在推理时检索相关段落，以改善知识密集型任务的性能。</li>
<li><strong>RAG的扩展</strong>：后续工作将RAG扩展到广泛的NLP范式中，包括动态适应检索的模块化和高级RAG变体，这些变体可以根据每个标记或每个查询动态调整检索。</li>
</ul>
<h3 id="模型上下文协议（MCP）的研究"><a href="#模型上下文协议（MCP）的研究" class="headerlink" title="模型上下文协议（MCP）的研究"></a>模型上下文协议（MCP）的研究</h3><ul>
<li><strong>MCP的介绍</strong>：MCP标准化了LLM与API之间的交互，将资源提示、身份验证和参数模式捆绑到模块化的“MCP”服务器中，这些服务器作为函数调用扩展，类似于OpenAI的函数调用API，但具有更大的社区可扩展性。</li>
<li><strong>MCP的评估报告</strong>：对MCP服务器的评估报告，提供了关于MCP服务器性能和功能的详细分析，为研究提供了基础数据和框架。</li>
</ul>
<p><strong>Q</strong>: 论文如何解决这个问题？</p>
<p><strong>A</strong>: 论文通过提出<strong>RAG-MCP框架</strong>来解决大型语言模型（LLMs）在使用大量外部工具时面临的“提示膨胀”和选择复杂性问题。以下是详细的解决方案：</p>
<h3 id="RAG-MCP框架概述"><a href="#RAG-MCP框架概述" class="headerlink" title="RAG-MCP框架概述"></a>RAG-MCP框架概述</h3><p>RAG-MCP框架的核心思想是通过**检索增强生成（Retrieval-Augmented Generation, RAG）**来动态检索与用户查询最相关的工具子集，而不是一次性将所有工具呈现给语言模型。具体步骤如下：</p>
<ol>
<li><p><strong>检索（Retrieval）</strong>：</p>
<ul>
<li>使用一个轻量级的LLM（例如Qwen）作为检索器，对用户的任务描述进行编码，并在外部的MCP索引中执行语义搜索。</li>
<li>检索器返回与任务描述最相似的前k个候选MCP工具。</li>
</ul>
</li>
<li><p><strong>验证（Validation）</strong>：</p>
<ul>
<li>对于每个检索到的MCP，RAG-MCP可以生成一些示例查询，并测试其响应，以确保基本兼容性。这可以看作是一个“合理性检查”，在调用之前验证工具的有效性。</li>
</ul>
</li>
<li><p><strong>调用（Invocation）</strong>：</p>
<ul>
<li>只将最相关的MCP描述（包括其工具使用参数）注入到LLM的提示中，然后LLM通过函数调用接口执行任务，无需关心工具发现。</li>
</ul>
</li>
</ol>
<h3 id="关键优势"><a href="#关键优势" class="headerlink" title="关键优势"></a>关键优势</h3><ul>
<li><strong>减少提示大小</strong>：通过只提供相关的MCP元数据，避免了上下文窗口过载，即使工具库很大，也不会导致提示膨胀。</li>
<li><strong>降低认知负荷</strong>：LLM不需要筛选数百个干扰项，从而提高了选择的准确性，减少了幻觉现象。</li>
<li><strong>资源效率</strong>：与传统的MCP客户端（例如Claude或早期的GPT-4集成）不同，RAG-MCP只激活选定的MCP，降低了启动成本，并且可以支持任意大小的工具集，而不会遇到基础设施瓶颈。</li>
<li><strong>多轮对话的鲁棒性</strong>：在多轮对话中，LLM不需要重新包含所有MCP提示；RAG-MCP的检索器动态处理工具回忆，释放上下文空间用于任务特定的推理。</li>
</ul>
<h3 id="实验验证"><a href="#实验验证" class="headerlink" title="实验验证"></a>实验验证</h3><p>论文通过一系列实验验证了RAG-MCP的有效性：</p>
<ol>
<li><p><strong>MCP压力测试</strong>：</p>
<ul>
<li>通过改变候选MCP服务器的数量N（从1到11100），并随机选择一个“真实”MCP和N-1个干扰MCP，测试模型选择正确MCP的能力。</li>
<li>实验结果表明，随着MCP池的增大，模型的选择能力显著下降，而RAG-MCP能够有效缓解这一问题。</li>
</ul>
</li>
<li><p><strong>基准测试</strong>：</p>
<ul>
<li>在MCPBench的Web搜索子集上评估了三种选择策略：空白条件（Blank Conditioning）、实际匹配（Actual Match）和RAG-MCP。</li>
<li>结果显示，RAG-MCP在准确性上显著优于其他基线方法，同时显著减少了提示令牌的使用。</li>
</ul>
</li>
</ol>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>RAG-MCP通过动态检索和验证相关工具，显著减少了提示大小，提高了工具选择的准确性，并保持了系统的可扩展性。这一框架为LLMs在面对大量外部工具时提供了一个有效的解决方案，使得模型能够更准确、高效地使用外部工具。</p>
<p><strong>Q</strong>: 论文做了哪些实验？</p>
<p><strong>A</strong>: 论文中进行了以下实验：</p>
<h3 id="1-MCP压力测试（Stress-Test）"><a href="#1-MCP压力测试（Stress-Test）" class="headerlink" title="1. MCP压力测试（Stress Test）"></a>1. <strong>MCP压力测试（Stress Test）</strong></h3><h4 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h4><p>量化大型语言模型（LLMs）在不同数量的候选MCP服务器下的工具选择能力，以评估提示膨胀（prompt bloat）对模型性能的影响。</p>
<h4 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h4><ul>
<li><strong>变量</strong>：候选MCP服务器的数量 NN  ，从1到11100，共26个区间。</li>
<li><strong>任务</strong>：Web搜索任务，要求模型选择正确的MCP服务器并执行任务。</li>
<li><strong>数据集</strong>：每个试验中，随机选择一个“真实”MCP（能够满足任务要求的唯一服务器）和 N−1N−1  个干扰MCP。</li>
<li><strong>试验次数</strong>：对于每个 NN  值，进行20次独立试验。</li>
<li><strong>成功标准</strong>：模型需要（a）选择正确的MCP，（b）发出有效的查询或答案，（c）返回最终结果。</li>
</ul>
<h4 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h4><ul>
<li><strong>高早期成功</strong>：当候选池较小时（MCP位置低于30），成功率超过90%。</li>
<li><strong>中期波动</strong>：在31到70的位置范围内，成功率开始下降，语义重叠导致选择错误。</li>
<li><strong>大规模性能下降</strong>：当MCP数量超过100时，成功率显著下降，表明在处理大量工具时，检索精度降低。</li>
<li><strong>残留成功区域</strong>：即使在较大的MCP池中，某些MCP仍然与特定查询高度相关，显示出一定的鲁棒性。</li>
</ul>
<h3 id="2-RAG-MCP性能评估"><a href="#2-RAG-MCP性能评估" class="headerlink" title="2. RAG-MCP性能评估"></a>2. <strong>RAG-MCP性能评估</strong></h3><h4 id="实验目的-1"><a href="#实验目的-1" class="headerlink" title="实验目的"></a>实验目的</h4><p>评估RAG-MCP框架在减少提示大小和提高工具选择准确性方面的有效性。</p>
<h4 id="实验设置-1"><a href="#实验设置-1" class="headerlink" title="实验设置"></a>实验设置</h4><ul>
<li><strong>数据集</strong>：MCPBench的Web搜索子集。</li>
<li><strong>基线方法</strong>：<ol>
<li><strong>空白条件（Blank Conditioning）</strong>：将所有 NN  个MCP描述一次性提供给LLM，让模型选择正确的MCP。</li>
<li><strong>实际匹配（Actual Match）</strong>：使用简单的关键词匹配预过滤候选池，然后将减少后的集合提供给模型。</li>
<li><strong>RAG-MCP</strong>：使用向量索引检索器对所有 NN  个MCP进行语义排序，并仅将排名最高的MCP描述注入LLM提示中。</li>
</ol>
</li>
<li><strong>试验次数</strong>：每个基线方法进行20次独立试验。</li>
<li><strong>成功标准</strong>：模型在20次试验中至少有10次正确选择MCP。</li>
<li><strong>评估指标</strong>：<ul>
<li><strong>准确性（%）</strong>：模型选择真实MCP的百分比。</li>
<li><strong>平均提示令牌数（Avg Prompt Tokens）</strong>：提示中消耗的平均令牌数，包括注入的MCP元数据。</li>
<li><strong>平均完成令牌数（Avg Completion Tokens）</strong>：模型生成的最终输出的平均令牌数。</li>
</ul>
</li>
</ul>
<h4 id="实验结果-1"><a href="#实验结果-1" class="headerlink" title="实验结果"></a>实验结果</h4><ul>
<li><strong>准确性</strong>：<ul>
<li><strong>RAG-MCP</strong>：43.13%</li>
<li><strong>实际匹配（Actual Match）</strong>：18.20%</li>
<li><strong>空白条件（Blank Conditioning）</strong>：13.62%</li>
</ul>
</li>
<li><strong>平均提示令牌数</strong>：<ul>
<li><strong>RAG-MCP</strong>：1084.00</li>
<li><strong>实际匹配（Actual Match）</strong>：1646.00</li>
<li><strong>空白条件（Blank Conditioning）</strong>：2133.84</li>
</ul>
</li>
<li><strong>平均完成令牌数</strong>：<ul>
<li><strong>RAG-MCP</strong>：78.14</li>
<li><strong>实际匹配（Actual Match）</strong>：23.60</li>
<li><strong>空白条件（Blank Conditioning）</strong>：162.25</li>
</ul>
</li>
</ul>
<h3 id="结论-1"><a href="#结论-1" class="headerlink" title="结论"></a>结论</h3><p>实验结果表明，RAG-MCP在减少提示大小和提高工具选择准确性方面显著优于其他基线方法。RAG-MCP通过动态检索和验证相关工具，显著减少了提示令牌的使用，并提高了模型选择正确工具的概率。这些结果验证了RAG-MCP框架在处理大量外部工具时的有效性和可扩展性。</p>
<p><strong>Q</strong>: 有什么可以进一步探索的点？</p>
<p><strong>A</strong>: 论文提出了RAG-MCP框架来解决LLMs在使用大量外部工具时的提示膨胀和选择复杂性问题，并通过实验验证了其有效性。然而，还有一些可以进一步探索的点，以进一步提升框架的性能和适用性：</p>
<h3 id="1-改进检索机制"><a href="#1-改进检索机制" class="headerlink" title="1. 改进检索机制"></a>1. <strong>改进检索机制</strong></h3><ul>
<li><strong>更复杂的检索算法</strong>：当前的RAG-MCP使用基于语义的向量空间检索。可以探索更复杂的检索算法，例如结合图神经网络（GNN）或层次化索引结构，以提高在大规模工具集中的检索精度。</li>
<li><strong>多模态检索</strong>：除了文本描述，工具的元数据可能还包括图像、图表等多模态信息。探索多模态检索技术，可能会进一步提高检索的准确性和效率。</li>
</ul>
<h3 id="2-动态工具选择策略"><a href="#2-动态工具选择策略" class="headerlink" title="2. 动态工具选择策略"></a>2. <strong>动态工具选择策略</strong></h3><ul>
<li><strong>自适应检索</strong>：根据任务的复杂性和上下文动态调整检索的深度和广度。例如，对于简单任务，可以减少检索的候选数量，而对于复杂任务，可以增加检索的范围。</li>
<li><strong>工具组合</strong>：当前的RAG-MCP主要关注单个工具的选择。在实际应用中，可能需要多个工具协同工作。探索如何动态选择和组合多个工具，以完成更复杂的任务。</li>
</ul>
<h3 id="3-实时更新和扩展性"><a href="#3-实时更新和扩展性" class="headerlink" title="3. 实时更新和扩展性"></a>3. <strong>实时更新和扩展性</strong></h3><ul>
<li><strong>实时索引更新</strong>：随着新工具的不断出现，需要实时更新索引以保持系统的最新状态。研究如何高效地将新工具元数据纳入索引，而无需重新训练整个模型。</li>
<li><strong>分布式索引</strong>：对于非常大的工具集，可以考虑使用分布式索引技术，将工具元数据分散存储在多个节点上，以提高检索效率和系统的可扩展性。</li>
</ul>
<h3 id="4-多轮对话中的工具选择"><a href="#4-多轮对话中的工具选择" class="headerlink" title="4. 多轮对话中的工具选择"></a>4. <strong>多轮对话中的工具选择</strong></h3><ul>
<li><strong>上下文记忆</strong>：在多轮对话中，模型需要记住之前选择的工具和执行的结果。研究如何在多轮对话中更好地管理上下文记忆，以提高工具选择的连贯性和准确性。</li>
<li><strong>动态调整</strong>：根据对话的进展动态调整工具选择策略，例如根据用户的反馈调整检索的优先级。</li>
</ul>
<h3 id="5-性能优化"><a href="#5-性能优化" class="headerlink" title="5. 性能优化"></a>5. <strong>性能优化</strong></h3><ul>
<li><strong>延迟优化</strong>：在大规模工具集中，检索和验证步骤可能会引入额外的延迟。研究如何优化这些步骤，以减少延迟并提高系统的响应速度。</li>
<li><strong>资源管理</strong>：在资源受限的环境中，如何优化资源分配，以确保系统在处理大量工具时的高效运行。</li>
</ul>
<h3 id="6-实际应用和部署"><a href="#6-实际应用和部署" class="headerlink" title="6. 实际应用和部署"></a>6. <strong>实际应用和部署</strong></h3><ul>
<li><strong>行业特定工具</strong>：在特定行业（如医疗、金融、教育等）中，工具的使用可能有特定的需求和限制。研究如何针对这些行业定制RAG-MCP框架，以更好地满足实际应用需求。</li>
<li><strong>用户反馈机制</strong>：在实际部署中，用户反馈对于改进系统性能至关重要。研究如何设计有效的用户反馈机制，以收集用户意见并据此优化工具选择和检索策略。</li>
</ul>
<h3 id="7-安全性和隐私保护"><a href="#7-安全性和隐私保护" class="headerlink" title="7. 安全性和隐私保护"></a>7. <strong>安全性和隐私保护</strong></h3><ul>
<li><strong>数据隐私</strong>：在检索和使用外部工具时，数据隐私是一个重要问题。研究如何在保护用户数据隐私的前提下，安全地检索和使用工具。</li>
<li><strong>工具验证</strong>：确保检索到的工具是可信的，防止恶意工具的注入。研究如何在检索过程中验证工具的来源和安全性。</li>
</ul>
<p>这些进一步探索的点不仅可以提升RAG-MCP框架的性能和适用性，还可以为LLMs在实际应用中的工具选择和使用提供更广泛的支持。</p>
<p><strong>Q</strong>: 总结一下论文的主要内容</p>
<p><strong>A</strong>: 本文介绍了RAG-MCP框架，旨在解决大型语言模型（LLMs）在使用大量外部工具时面临的提示膨胀（prompt bloat）和选择复杂性问题。RAG-MCP通过检索增强生成（Retrieval-Augmented Generation, RAG）技术，动态检索与用户查询最相关的工具子集，而不是一次性将所有工具呈现给语言模型，从而减少上下文长度和复杂性，提高模型的决策能力。</p>
<h3 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h3><ul>
<li><strong>LLMs的局限性</strong>：LLMs在自然对话、推理和代码生成方面表现出色，但受限于其参数中编码的知识和固定的上下文窗口。为了克服这一限制，研究者们开始将LLMs与外部工具（如API）集成，以获取最新信息和执行复杂操作。</li>
<li><strong>工具使用挑战</strong>：随着工具数量的增加，将所有工具的定义或使用说明都包含在模型的上下文中会导致上下文窗口被大量无关信息占据，降低模型区分和回忆正确工具的能力。此外，过多的工具选择会使模型在决定是否调用以及调用哪个工具时面临更复杂的决策过程，增加错误选择或误解工具功能的风险。</li>
</ul>
<h3 id="研究方法"><a href="#研究方法" class="headerlink" title="研究方法"></a>研究方法</h3><ul>
<li><strong>RAG-MCP框架</strong>：该框架的核心思想是通过语义检索来识别与给定查询最相关的MCP工具，然后只将这些工具的描述传递给LLM，从而显著减少提示大小并简化决策过程。<ol>
<li><strong>检索（Retrieval）</strong>：使用轻量级LLM对用户任务描述进行编码，并在外部MCP索引中执行语义搜索，返回最相似的前k个候选MCP。</li>
<li><strong>验证（Validation）</strong>：对每个检索到的MCP生成示例查询并测试其响应，确保基本兼容性。</li>
<li><strong>调用（Invocation）</strong>：只将最相关的MCP描述注入LLM提示中，然后LLM通过函数调用接口执行任务。</li>
</ol>
</li>
</ul>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><ul>
<li><strong>MCP压力测试</strong>：通过改变候选MCP服务器的数量N（从1到11100），并随机选择一个“真实”MCP和N-1个干扰MCP，测试模型选择正确MCP的能力。实验结果表明，随着MCP池的增大，模型的选择能力显著下降，而RAG-MCP能够有效缓解这一问题。</li>
<li><strong>基准测试</strong>：在MCPBench的Web搜索子集上评估了三种选择策略：空白条件（Blank Conditioning）、实际匹配（Actual Match）和RAG-MCP。结果表明，RAG-MCP在准确性上显著优于其他基线方法，同时显著减少了提示令牌的使用。</li>
</ul>
<h3 id="关键结论"><a href="#关键结论" class="headerlink" title="关键结论"></a>关键结论</h3><ul>
<li><strong>减少提示大小</strong>：RAG-MCP通过只提供相关的MCP元数据，避免了上下文窗口过载，即使工具库很大，也不会导致提示膨胀。</li>
<li><strong>降低认知负荷</strong>：LLM不需要筛选数百个干扰项，从而提高了选择的准确性，减少了幻觉现象。</li>
<li><strong>资源效率</strong>：与传统的MCP客户端不同，RAG-MCP只激活选定的MCP，降低了启动成本，并且可以支持任意大小的工具集，而不会遇到基础设施瓶颈。</li>
<li><strong>多轮对话的鲁棒性</strong>：在多轮对话中，LLM不需要重新包含所有MCP提示；RAG-MCP的检索器动态处理工具回忆，释放上下文空间用于任务特定的推理。</li>
</ul>
<h3 id="未来工作"><a href="#未来工作" class="headerlink" title="未来工作"></a>未来工作</h3><ul>
<li><strong>改进检索机制</strong>：探索更复杂的检索算法，如结合图神经网络或层次化索引结构，以提高在大规模工具集中的检索精度。</li>
<li><strong>动态工具选择策略</strong>：研究如何动态选择和组合多个工具，以完成更复杂的任务。</li>
<li><strong>实时更新和扩展性</strong>：研究如何实时更新索引以保持系统的最新状态，并探索分布式索引技术以提高检索效率和系统的可扩展性。</li>
<li><strong>多轮对话中的工具选择</strong>：研究如何在多轮对话中更好地管理上下文记忆，以提高工具选择的连贯性和准确性。</li>
<li><strong>性能优化</strong>：优化检索和验证步骤，以减少延迟并提高系统的响应速度。</li>
<li><strong>实际应用和部署</strong>：针对特定行业定制RAG-MCP框架，以更好地满足实际应用需求，并设计有效的用户反馈机制以优化工具选择和检索策略。</li>
<li><strong>安全性和隐私保护</strong>：研究如何在保护用户数据隐私的前提下，安全地检索和使用工具，并在检索过程中验证工具的来源和安全性。</li>
</ul>
<p><strong>Q</strong>: 想要进一步了解论文</p>
<p><strong>A</strong>: 以上只是了解一篇论文的几个基本FAQ。如果你还想与Kimi进一步讨论该论文，请点击 <a target="_blank" rel="noopener" href="http://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%20%E6%88%91%E4%BB%AC%E8%A6%81%E8%AE%A8%E8%AE%BA%E7%9A%84%E8%AE%BA%E6%96%87%E6%98%AFRAG-MCP:%20Mitigating%20Prompt%20Bloat%20in%20LLM%20Tool%20Selection%20via%20Retrieval-Augmented%20Generation%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF%20%20https://arxiv.org/pdf/2505.03275%20%20%EF%BC%8C%E5%B7%B2%E6%9C%89%E7%9A%84FAQ%E9%93%BE%E6%8E%A5%E6%98%AF%20%20https://papers.cool/arxiv/kimi?paper=2505.03275%20%20%E3%80%82%E8%AF%B7%E4%BB%A5%E6%AD%A4%E4%B8%BA%E5%9F%BA%E7%A1%80%EF%BC%8C%E7%BB%A7%E7%BB%AD%E5%9B%9E%E7%AD%94%E6%88%91%E5%90%8E%E9%9D%A2%E7%9A%84%E9%97%AE%E9%A2%98%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E5%8A%A9%E6%89%8B%EF%BC%8C%E5%90%8E%E9%9D%A2%E7%9A%84%E5%AF%B9%E8%AF%9D%E5%B0%86%E5%9B%B4%E7%BB%95%E7%9D%80%E4%BB%A5%E4%B8%8B%E8%AE%BA%E6%96%87%E5%86%85%E5%AE%B9%E8%BF%9B%E8%A1%8C%EF%BC%8C%E5%B7%B2%E7%BB%8F%E9%80%9A%E8%BF%87%E9%93%BE%E6%8E%A5%E7%BB%99%E5%87%BA%E4%BA%86%E8%AE%BA%E6%96%87%E7%9A%84PDF%E5%92%8C%E8%AE%BA%E6%96%87%E5%B7%B2%E6%9C%89%E7%9A%84FAQ%E3%80%82%E7%94%A8%E6%88%B7%E5%B0%86%E7%BB%A7%E7%BB%AD%E5%90%91%E4%BD%A0%E5%92%A8%E8%AF%A2%E8%AE%BA%E6%96%87%E7%9A%84%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BD%9C%E5%87%BA%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82&send_immediately=true&force_search=false"><strong>这里</strong></a> 为你跳转Kimi AI网页版，并启动一个与该论文相关的新会话。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">QianLi Yang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://yangqianli92.github.io/">https://yangqianli92.github.io/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">QianLi Yang</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/LLM/">LLM</a><a class="post-meta__tags" href="/tags/Paper/">Paper</a></div><div class="post-share"><div class="social-share" data-image="/images/head.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/06/03/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A01/" title="LLM论文阅读-狼人杀系列 强化学习智能体在狼人杀中的策略玩法"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">LLM论文阅读-狼人杀系列 强化学习智能体在狼人杀中的策略玩法</div></div><div class="info-2"><div class="info-item-1">#1 Language Agents with Reinforcement Learning for Strategic Play in the Werewolf GameAuthors: Zelai Xu, Chao Yu, Fei Fang, Yu Wang, Yi Wu Agents built with large language models (LLMs) have shown great potential across a wide range of domains. However, in complex decision-making tasks, pure LLM-based agents tend to exhibit intrinsic bias in their choice of actions, which is inherited from the model’s training data and results in suboptimal performance. To develop strategic language agents,...</div></div></div></a><a class="pagination-related" href="/2025/05/29/function_calling/" title="LLM实践:function calling工具调用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">LLM实践:function calling工具调用</div></div><div class="info-2"><div class="info-item-1">Function Calling工具使用，也称为函数调用(Function calling)，是指通过定义和调用外部工具或函数来扩展大模型的能力。我们可以为大模型提供一组预定义工具的访问权限，它可以随时调用这些工具。工具允许我们编写代码，这些代码可以执行大模型无法执行的特定任务或计算。简而言之：工具使用是增强大模型功能的一种方式。  工具调用通常具有以下几个特性：1 拓展大模型的功能：使用工具可以让大模型的功能超越其内置功能。通过定义和调用外部工具，您可以使大模型能够执行原本无法完成的任务 2 与现有系统集成：使用工具可以实现大模型与您现有系统、数据库或 API 的无缝集成 3...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/06/03/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A01/" title="LLM论文阅读-狼人杀系列 强化学习智能体在狼人杀中的策略玩法"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-03</div><div class="info-item-2">LLM论文阅读-狼人杀系列 强化学习智能体在狼人杀中的策略玩法</div></div><div class="info-2"><div class="info-item-1">#1 Language Agents with Reinforcement Learning for Strategic Play in the Werewolf GameAuthors: Zelai Xu, Chao Yu, Fei Fang, Yu Wang, Yi Wu Agents built with large language models (LLMs) have shown great potential across a wide range of domains. However, in complex decision-making tasks, pure LLM-based agents tend to exhibit intrinsic bias in their choice of actions, which is inherited from the model’s training data and results in suboptimal performance. To develop strategic language agents,...</div></div></div></a><a class="pagination-related" href="/2025/06/10/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A02/" title="LLM论文阅读-狼人杀系列 探索LLM在社交类游戏的应用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-10</div><div class="info-item-2">LLM论文阅读-狼人杀系列 探索LLM在社交类游戏的应用</div></div><div class="info-2"><div class="info-item-1">Exploring Large Language Models for Communication Games: An Empirical Study on Werewolf  Authors: Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang, Weidong Liu, Yang Liu Communication games, which we refer to as incomplete information games that heavily depend on natural language communication, hold significant research value in fields such as economics, social science, and artificial intelligence. In this work, we explore the problem of how to engage large language models (LLMs) in...</div></div></div></a><a class="pagination-related" href="/2025/06/12/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A03/" title="LLM论文阅读-狼人杀系列 Werewolf 一个直观的游戏框架，配备文本转语音功能以提升用户参与度"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-12</div><div class="info-item-2">LLM论文阅读-狼人杀系列 Werewolf 一个直观的游戏框架，配备文本转语音功能以提升用户参与度</div></div><div class="info-2"><div class="info-item-1">Werewolf: A Straightforward Game Framework with TTS for Improved User Engagement  Authors: Qihui Fan, Enfu Nan, Wenbo Li, Lei Lu, Pu Zhao, Yanzhi Wang The growing popularity of social deduction game systems for both business applications and AI research has greatly benefited from the rapid advancements in Large Language Models (LLMs), which now demonstrate stronger reasoning and persuasion capabilities. Especially with the raise of DeepSeek R1 and V3 models, LLMs should enable a more...</div></div></div></a><a class="pagination-related" href="/2025/06/16/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A05/" title="LLM论文阅读-狼人杀系列5 Werewolf Arena"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-16</div><div class="info-item-2">LLM论文阅读-狼人杀系列5 Werewolf Arena</div></div><div class="info-2"><div class="info-item-1">Werewolf Arena: A Case Study in LLM Evaluation via Social Deduction Authors: Suma Bailis, Jane Friedhoff, Feiyang Chen This paper introduces Werewolf Arena, a novel framework for evaluating large language models (LLMs) through the lens of the classic social deduction game, Werewolf. In Werewolf Arena, LLMs compete against each other, navigating the game’s complex dynamics of deception, deduction, and persuasion. The framework introduces a dynamic turn-taking system based on bidding,...</div></div></div></a><a class="pagination-related" href="/2025/06/16/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A04/" title="LLM论文阅读-狼人杀系列4 利用多智能体强化学习训练社交推理语言模型"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-16</div><div class="info-item-2">LLM论文阅读-狼人杀系列4 利用多智能体强化学习训练社交推理语言模型</div></div><div class="info-2"><div class="info-item-1">Training Language Models for Social Deduction with Multi-Agent Reinforcement LearningAuthors: Bidipta Sarkar, Warren Xia, C. Karen Liu, Dorsa Sadigh Communicating in natural language is a powerful tool in multi-agent settings, as it enables independent agents to share information in partially observable settings and allows zero-shot coordination with humans. However, most prior works are limited as they either rely on training with large amounts of human demonstrations or lack the ability to...</div></div></div></a><a class="pagination-related" href="/2025/06/15/o1%E5%8E%9F%E7%90%86/" title="GPT-o1原理学习"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-15</div><div class="info-item-2">GPT-o1原理学习</div></div><div class="info-2"><div class="info-item-1">GPT-o1原理OpenAI o1原理逆向工程图解的分析，O1的训练过程可归纳为以下阶段和核心机制：  一、预训练阶段（Pre-training） 数据配比调整O1的基座模型重新训练（非GPT-4o微调），大幅增加逻辑类数据（如STEM学科、代码、论文），减少通用知识数据，导致O1 mini“逻辑推理极强但世界知识弱”。 目标与传统LLM一致通过Next Token Prediction学习语言、基础推理等能力，但通过数据优化侧重逻辑内化。   二、后训练阶段（Post-training） 指令微调（SFT）   使用逻辑推理类指令数据增强模型遵循指令的能力，为后续生成Hidden CoT铺垫。  Let’s Verify Step by Step技术继承  数据风格：中间过程采用口语化、长文本、含反思纠错的结构（例：”wait a...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/images/head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">QianLi Yang</div><div class="author-info-description">不定时更新程序员成长之路~</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">16</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/YangQianli92" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:chainllie92@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/Serein_Young" target="_blank" title="Wechat"><i class="fab fa-weixin"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#RAG-MCP-Mitigating-Prompt-Bloat-in-LLM-Tool-Selection-via-Retrieval-Augmented-Generation-PDF5-Copy-Kimi19-REL"><span class="toc-number">1.</span> <span class="toc-text">RAG-MCP: Mitigating Prompt Bloat in LLM Tool Selection via Retrieval-Augmented Generation [PDF5] [Copy] [Kimi19] [REL]</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E5%9C%A8LLMs%E4%B8%AD%E7%9A%84%E7%A0%94%E7%A9%B6"><span class="toc-number">1.1.</span> <span class="toc-text">工具使用在LLMs中的研究</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%EF%BC%88RAG%EF%BC%89%E7%9A%84%E7%A0%94%E7%A9%B6"><span class="toc-number">1.2.</span> <span class="toc-text">检索增强生成（RAG）的研究</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE%EF%BC%88MCP%EF%BC%89%E7%9A%84%E7%A0%94%E7%A9%B6"><span class="toc-number">1.3.</span> <span class="toc-text">模型上下文协议（MCP）的研究</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RAG-MCP%E6%A1%86%E6%9E%B6%E6%A6%82%E8%BF%B0"><span class="toc-number">1.4.</span> <span class="toc-text">RAG-MCP框架概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E4%BC%98%E5%8A%BF"><span class="toc-number">1.5.</span> <span class="toc-text">关键优势</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E9%AA%8C%E8%AF%81"><span class="toc-number">1.6.</span> <span class="toc-text">实验验证</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-number">1.7.</span> <span class="toc-text">结论</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-MCP%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%EF%BC%88Stress-Test%EF%BC%89"><span class="toc-number">1.8.</span> <span class="toc-text">1. MCP压力测试（Stress Test）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%9B%AE%E7%9A%84"><span class="toc-number">1.8.1.</span> <span class="toc-text">实验目的</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E8%AE%BE%E7%BD%AE"><span class="toc-number">1.8.2.</span> <span class="toc-text">实验设置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-number">1.8.3.</span> <span class="toc-text">实验结果</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-RAG-MCP%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0"><span class="toc-number">1.9.</span> <span class="toc-text">2. RAG-MCP性能评估</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%9B%AE%E7%9A%84-1"><span class="toc-number">1.9.1.</span> <span class="toc-text">实验目的</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E8%AE%BE%E7%BD%AE-1"><span class="toc-number">1.9.2.</span> <span class="toc-text">实验设置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C-1"><span class="toc-number">1.9.3.</span> <span class="toc-text">实验结果</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA-1"><span class="toc-number">1.10.</span> <span class="toc-text">结论</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%94%B9%E8%BF%9B%E6%A3%80%E7%B4%A2%E6%9C%BA%E5%88%B6"><span class="toc-number">1.11.</span> <span class="toc-text">1. 改进检索机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%8A%A8%E6%80%81%E5%B7%A5%E5%85%B7%E9%80%89%E6%8B%A9%E7%AD%96%E7%95%A5"><span class="toc-number">1.12.</span> <span class="toc-text">2. 动态工具选择策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%AE%9E%E6%97%B6%E6%9B%B4%E6%96%B0%E5%92%8C%E6%89%A9%E5%B1%95%E6%80%A7"><span class="toc-number">1.13.</span> <span class="toc-text">3. 实时更新和扩展性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B8%AD%E7%9A%84%E5%B7%A5%E5%85%B7%E9%80%89%E6%8B%A9"><span class="toc-number">1.14.</span> <span class="toc-text">4. 多轮对话中的工具选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96"><span class="toc-number">1.15.</span> <span class="toc-text">5. 性能优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E5%92%8C%E9%83%A8%E7%BD%B2"><span class="toc-number">1.16.</span> <span class="toc-text">6. 实际应用和部署</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E5%AE%89%E5%85%A8%E6%80%A7%E5%92%8C%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4"><span class="toc-number">1.17.</span> <span class="toc-text">7. 安全性和隐私保护</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86"><span class="toc-number">1.18.</span> <span class="toc-text">背景知识</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A0%94%E7%A9%B6%E6%96%B9%E6%B3%95"><span class="toc-number">1.19.</span> <span class="toc-text">研究方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C"><span class="toc-number">1.20.</span> <span class="toc-text">实验</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E7%BB%93%E8%AE%BA"><span class="toc-number">1.21.</span> <span class="toc-text">关键结论</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%AA%E6%9D%A5%E5%B7%A5%E4%BD%9C"><span class="toc-number">1.22.</span> <span class="toc-text">未来工作</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/16/%E6%A2%A6%E5%B9%BB%E8%A5%BF%E6%B8%B8/" title="无标题">无标题</a><time datetime="2025-06-16T14:56:44.947Z" title="发表于 2025-06-16 22:56:44">2025-06-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/16/%E7%8B%BC%E4%BA%BA%E6%9D%80/" title="基于大语言模型（LLM）驱动的AI狼人杀综述">基于大语言模型（LLM）驱动的AI狼人杀综述</a><time datetime="2025-06-16T09:31:08.000Z" title="发表于 2025-06-16 17:31:08">2025-06-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/16/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A05/" title="LLM论文阅读-狼人杀系列5 Werewolf Arena">LLM论文阅读-狼人杀系列5 Werewolf Arena</a><time datetime="2025-06-16T04:46:48.000Z" title="发表于 2025-06-16 12:46:48">2025-06-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/16/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A04/" title="LLM论文阅读-狼人杀系列4 利用多智能体强化学习训练社交推理语言模型">LLM论文阅读-狼人杀系列4 利用多智能体强化学习训练社交推理语言模型</a><time datetime="2025-06-16T04:46:48.000Z" title="发表于 2025-06-16 12:46:48">2025-06-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/15/o1%E5%8E%9F%E7%90%86/" title="GPT-o1原理学习">GPT-o1原理学习</a><time datetime="2025-06-15T08:35:48.000Z" title="发表于 2025-06-15 16:35:48">2025-06-15</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By QianLi Yang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>