<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>LLM论文阅读-狼人杀系列 探索LLM在社交类游戏的应用 | QianLi Yang</title><meta name="author" content="QianLi Yang"><meta name="copyright" content="QianLi Yang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Exploring Large Language Models for Communication Games: An Empirical Study on Werewolf  Authors: Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang, Weidong Liu, Yang Liu Communication games,">
<meta property="og:type" content="article">
<meta property="og:title" content="LLM论文阅读-狼人杀系列 探索LLM在社交类游戏的应用">
<meta property="og:url" content="http://example.com/2025/06/10/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A02/index.html">
<meta property="og:site_name" content="QianLi Yang">
<meta property="og:description" content="Exploring Large Language Models for Communication Games: An Empirical Study on Werewolf  Authors: Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang, Weidong Liu, Yang Liu Communication games,">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/images/head.jpg">
<meta property="article:published_time" content="2025-06-10T04:46:48.000Z">
<meta property="article:modified_time" content="2025-06-16T13:53:52.060Z">
<meta property="article:author" content="QianLi Yang">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="Paper">
<meta property="article:tag" content="werewolf">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/head.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2025/06/10/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A02/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'LLM论文阅读-狼人杀系列 探索LLM在社交类游戏的应用',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: false,
  isShuoshuo: false
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/images/head.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">17</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://github.com/YangQianli92"><i class="fa-fw fab fa-github"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">QianLi Yang</span></a><a class="nav-page-title" href="/"><span class="site-name">LLM论文阅读-狼人杀系列 探索LLM在社交类游戏的应用</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://github.com/YangQianli92"><i class="fa-fw fab fa-github"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">LLM论文阅读-狼人杀系列 探索LLM在社交类游戏的应用</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-06-10T04:46:48.000Z" title="发表于 2025-06-10 12:46:48">2025-06-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-06-16T13:53:52.060Z" title="更新于 2025-06-16 21:53:52">2025-06-16</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2309.04658">Exploring Large Language Models for Communication Games: An Empirical Study on Werewolf</a> </p>
<p><strong>Authors</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/search/?searchtype=author&query=Yuzhuang%20Xu">Yuzhuang Xu</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/?searchtype=author&query=Shuo%20Wang">Shuo Wang</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/?searchtype=author&query=Peng%20Li">Peng Li</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/?searchtype=author&query=Fuwen%20Luo">Fuwen Luo</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/?searchtype=author&query=Xiaolong%20Wang">Xiaolong Wang</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/?searchtype=author&query=Weidong%20Liu">Weidong Liu</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/?searchtype=author&query=Yang%20Liu">Yang Liu</a></p>
<p>Communication games, which we refer to as incomplete information games that heavily depend on natural language communication, hold significant research value in fields such as economics, social science, and artificial intelligence. In this work, we explore the problem of how to engage large language models (LLMs) in communication games, and in response, propose a tuning-free framework. Our approach keeps LLMs frozen, and relies on the retrieval and reflection on past communications and experiences for improvement. An empirical study on the representative and widely-studied communication game, ``Werewolf’’, demonstrates that our framework can effectively play Werewolf game without tuning the parameters of the LLMs. More importantly, strategic behaviors begin to emerge in our experiments, suggesting that it will be a fruitful journey to engage LLMs in communication games and associated domains.</p>
<p><strong>Subject</strong>: <a target="_blank" rel="noopener" href="https://papers.cool/arxiv/cs.CL">Computation and Language</a></p>
<p><strong>Publish</strong>: 2023-09-09 01:56:40 UTC</p>
<p><strong>Q</strong>: 这篇论文试图解决什么问题？</p>
<p><strong>A</strong>: 这篇论文探讨了如何将大型语言模型（Large Language Models，LLMs）应用于通信游戏（communication games），特别是针对一种名为“狼人杀”（Werewolf）的不完全信息游戏。通信游戏是一类依赖于自然语言交流的不完全信息游戏，在经济学、社会科学和人工智能等领域具有重要的研究价值。然而，现有的研究在语言使用上施加了严格限制或需要大量的人工标注数据，使得AI代理以自然的方式参与这类游戏仍然具有挑战性。</p>
<p>论文的主要问题和挑战包括：</p>
<ol>
<li><p><strong>有限的上下文长度</strong>：LLMs的最大输入长度限制了单次能够处理的信息量。在通信游戏中，历史信息对于决策至关重要，但这些信息往往过于庞大，无法被LLMs一次性处理。</p>
</li>
<li><p><strong>复杂推理</strong>：理解其他玩家的意图并做出适当的决策以赢得游戏需要复杂的推理，这对LLMs来说是一个挑战。</p>
</li>
<li><p><strong>从经验中学习</strong>：LLMs可能像人类一样从经验中学习，以改进其行为。但是，微调（fine-tuning）LLMs既不现实也不高效，因为它既耗时又需要大量数据。</p>
</li>
</ol>
<p>为了解决这些问题，论文提出了一个无需调整参数的框架，通过检索和反思过去的通信和经验来改进LLMs的表现。通过在“狼人杀”游戏中的实证研究，论文展示了该框架能够在不调整LLMs参数的情况下有效进行游戏，并且战略行为开始在实验中显现，这表明将LLMs引入通信游戏及其相关领域将是一段富有成果的旅程。</p>
<p><strong>Q</strong>: 论文如何解决这个问题？</p>
<p><strong>A</strong>: 论文提出了一个无需调整参数的框架来解决大型语言模型（LLMs）参与通信游戏的问题。具体方法如下：</p>
<ol>
<li><p><strong>保持LLMs固定</strong>：不通过微调LLMs的参数来改进它们的表现，而是依靠检索和反思过去的通信及经验来实现改进。</p>
</li>
<li><p><strong>历史信息收集</strong>：由于LLMs的上下文长度有限，论文提出了从新鲜感（freshness）、信息量（informativeness）和完整性（completeness）三个角度收集历史信息的方法。这包括：</p>
<ul>
<li><strong>新鲜感</strong>：包含最近的K条消息。</li>
<li><strong>信息量</strong>：通过规则匹配和启发式度量收集易识别的、携带关键信息的消息。</li>
<li><strong>完整性</strong>：通过回答问题的方式来提取整个历史中的更多信息，生成每个代理的“反思”（reflection）。</li>
</ul>
</li>
<li><p><strong>从经验中学习</strong>：提出了一种非参数学习机制，使LLMs能够在不调整模型参数的情况下参考过去的经验。这包括：</p>
<ul>
<li><strong>构建经验池</strong>：收集并评分每个代理在每轮游戏结束时的响应和反思，形成经验池。</li>
<li><strong>提取建议</strong>：从经验池中检索与当前情况最相关的经历，并提取建议来指导代理的推理。</li>
</ul>
</li>
<li><p><strong>实验验证</strong>：通过在“狼人杀”游戏中的实验，展示了LLMs在不调整参数的情况下，通过框架学习从经验中改进的能力，并观察到战略行为的出现。</p>
</li>
<li><p><strong>战略行为的观察</strong>：论文还观察到LLMs在游戏中表现出了信任（trust）、对抗（confrontation）、伪装（camouflage）和领导（leadership）等战略行为，这些行为并非在游戏规则或提示中明确预设，而是LLMs在游戏中自发形成的。</p>
</li>
</ol>
<p>通过这些方法，论文展示了LLMs在通信游戏中的潜力，并为未来的研究提供了新的方向。</p>
<p><strong>Q</strong>: 论文做了哪些实验？</p>
<p><strong>A</strong>: 论文中进行了一系列实验来验证所提出的框架在“狼人杀”游戏中的有效性，并分析了从经验中学习对LLMs性能的影响。以下是论文中提到的主要实验：</p>
<ol>
<li><p><strong>经验池构建实验</strong>：</p>
<ul>
<li>通过不同数量的游戏轮次（10、20、30、40轮）来构建经验池。</li>
<li>在每轮游戏中随机分配玩家角色，并在每轮结束时更新经验池。</li>
<li>为了评估框架从经验中学习的效果，让村民、预言家、守卫和女巫角色使用经验池，而狼人角色不使用。</li>
</ul>
</li>
<li><p><strong>使用经验的效果分析</strong>：</p>
<ul>
<li>使用胜率和游戏持续时间作为性能指标。</li>
<li>运行实验50轮，并记录不同经验池大小对胜率和游戏持续时间的影响。</li>
</ul>
</li>
<li><p><strong>对抗性分析</strong>：</p>
<ul>
<li>分析了不同角色（村民和狼人）在游戏过程中的伪装行为（camouflage）变化趋势。</li>
<li>探讨了多LLMs参与多方游戏时，LLMs能力的变化情况。</li>
</ul>
</li>
<li><p><strong>消融研究</strong>：</p>
<ul>
<li>对方法的每个组成部分进行了定性和定量分析，以验证每个部分的必要性。</li>
<li>通过移除方法中的各个组成部分，并观察对模型输出的影响。</li>
</ul>
</li>
<li><p><strong>战略行为的观察</strong>：</p>
<ul>
<li>观察了LLMs在游戏中表现出的非预设战略行为，包括信任（trust）、对抗（confrontation）、伪装（camouflage）和领导（leadership）。</li>
<li>通过修改提示中角色名称来测试这些行为是否源自LLMs的训练数据。</li>
</ul>
</li>
<li><p><strong>实验设置</strong>：</p>
<ul>
<li>使用了Chatarena框架来实现设计，并连接多个LLMs。</li>
<li>使用gpt-3.5-turbo-0301模型作为后端LLMs。</li>
</ul>
</li>
<li><p><strong>定量分析</strong>：</p>
<ul>
<li>对比了完整方法与移除特定组件的变体，通过人类评估来判断输出的合理性。</li>
</ul>
</li>
</ol>
<p>这些实验结果表明，所提出的框架能够有效地在不调整LLMs参数的情况下，通过从经验中学习来提高在“狼人杀”游戏中的表现。同时，实验还揭示了LLMs在游戏中展现出的高级战略行为。</p>
<p><strong>Q</strong>: 有什么可以进一步探索的点？</p>
<p><strong>A</strong>: 根据论文的讨论和结论部分，以下是一些可以进一步探索的点：</p>
<ol>
<li><p><strong>高级游戏技巧的掌握</strong>：研究如何使LLM掌握高级游戏技巧，例如通过向人类玩家学习经验或自主探索。</p>
</li>
<li><p><strong>构建不变基线</strong>：探索如何构建一个不变的基线（invariant baseline），以评估多LLMs设置中的能力。</p>
</li>
<li><p><strong>减少幻觉的影响</strong>：研究如何最小化幻觉（hallucinations）对生成内容事实性的影响，并促进LLMs在现实世界场景中的应用。</p>
</li>
<li><p><strong>更有效地利用历史经验</strong>：探索如何更有效地利用历史经验，例如减轻噪声的不利影响，以及利用跨游戏的通用经验。</p>
</li>
<li><p><strong>人类玩家经验池的整合</strong>：在未来的研究中，考虑将来自人类玩家的经验池整合进来，以增强LLMs的性能和策略。</p>
</li>
<li><p><strong>更复杂的游戏环境</strong>：将所提出的方法应用于更广泛的游戏，以及进一步增强其游戏能力。</p>
</li>
<li><p><strong>与人类玩家的比较</strong>：进行更深入的研究，比较LLMs与人类玩家在游戏中的表现，以评估LLMs的能力和局限性。</p>
</li>
<li><p><strong>改进学习机制</strong>：研究改进LLMs从经验中学习的机制，例如通过更复杂的提示和启发式评分系统。</p>
</li>
<li><p><strong>多模态输入的处理</strong>：考虑将多模态输入（如视觉和听觉信息）整合到游戏环境中，以测试和提高LLMs的多模态理解能力。</p>
</li>
<li><p><strong>伦理和安全问题</strong>：随着LLMs在游戏中的应用越来越广泛，需要进一步探讨伦理和安全问题，确保技术的发展符合道德标准和社会责任。</p>
</li>
</ol>
<p>这些探索点不仅可以推动LLMs在通信游戏领域的研究，还可能对人工智能在更广泛领域的应用产生影响。</p>
<p><strong>Q</strong>: 总结一下论文的主要内容</p>
<p><strong>A</strong>: 这篇论文的主要内容可以总结如下：</p>
<ol>
<li><p><strong>问题背景</strong>：论文探讨了如何将大型语言模型（LLMs）应用于通信游戏，特别是“狼人杀”这类不完全信息游戏。这类游戏在经济学、社会科学和人工智能等领域具有重要的研究价值。</p>
</li>
<li><p><strong>研究挑战</strong>：LLMs在参与通信游戏时面临挑战，包括有限的上下文长度限制、复杂推理需求以及从经验中学习的能力。</p>
</li>
<li><p><strong>提出框架</strong>：论文提出了一个无需调整参数的框架，通过检索和反思过去的通信及经验来改进LLMs的表现。</p>
</li>
<li><p><strong>历史信息收集</strong>：提出了从新鲜感、信息量和完整性三个角度收集历史信息的方法，以解决LLMs上下文长度限制的问题。</p>
</li>
<li><p><strong>从经验中学习</strong>：设计了一种非参数学习机制，使LLMs能够在不调整模型参数的情况下参考过去的经验。</p>
</li>
<li><p><strong>实验验证</strong>：通过在“狼人杀”游戏中的实验，验证了框架的有效性，并观察到战略行为的出现。</p>
</li>
<li><p><strong>战略行为观察</strong>：论文还观察到LLMs在游戏中表现出了信任、对抗、伪装和领导等战略行为，这些行为并非在游戏规则或提示中明确预设。</p>
</li>
<li><p><strong>消融研究</strong>：通过定性和定量分析，验证了方法中每个组成部分的必要性。</p>
</li>
<li><p><strong>未来工作</strong>：论文指出了未来研究的方向，包括如何使LLM掌握高级游戏技巧、构建不变基线、减少幻觉的影响等。</p>
</li>
<li><p><strong>局限性和伦理声明</strong>：论文讨论了当前方法的局限性，并提供了一个伦理声明，强调游戏设置仅用于娱乐和研究目的，作者不容忍任何形式的现实生活暴力或非法活动。</p>
</li>
</ol>
<p>论文通过提出一个创新的框架，并在“狼人杀”游戏中进行实证研究，展示了LLMs在通信游戏中的潜力，并为未来的研究提供了新的方向。</p>
<p>**</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">QianLi Yang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://yangqianli92.github.io/">https://yangqianli92.github.io/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">QianLi Yang</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/LLM/">LLM</a><a class="post-meta__tags" href="/tags/Paper/">Paper</a><a class="post-meta__tags" href="/tags/werewolf/">werewolf</a></div><div class="post-share"><div class="social-share" data-image="/images/head.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/06/12/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A03/" title="LLM论文阅读-狼人杀系列 Werewolf 一个直观的游戏框架，配备文本转语音功能以提升用户参与度"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">LLM论文阅读-狼人杀系列 Werewolf 一个直观的游戏框架，配备文本转语音功能以提升用户参与度</div></div><div class="info-2"><div class="info-item-1">Werewolf: A Straightforward Game Framework with TTS for Improved User Engagement  Authors: Qihui Fan, Enfu Nan, Wenbo Li, Lei Lu, Pu Zhao, Yanzhi Wang The growing popularity of social deduction game systems for both business applications and AI research has greatly benefited from the rapid advancements in Large Language Models (LLMs), which now demonstrate stronger reasoning and persuasion capabilities. Especially with the raise of DeepSeek R1 and V3 models, LLMs should enable a more...</div></div></div></a><a class="pagination-related" href="/2025/06/03/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A01/" title="LLM论文阅读-狼人杀系列 强化学习智能体在狼人杀中的策略玩法"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">LLM论文阅读-狼人杀系列 强化学习智能体在狼人杀中的策略玩法</div></div><div class="info-2"><div class="info-item-1">#1 Language Agents with Reinforcement Learning for Strategic Play in the Werewolf GameAuthors: Zelai Xu, Chao Yu, Fei Fang, Yu Wang, Yi Wu Agents built with large language models (LLMs) have shown great potential across a wide range of domains. However, in complex decision-making tasks, pure LLM-based agents tend to exhibit intrinsic bias in their choice of actions, which is inherited from the model’s training data and results in suboptimal performance. To develop strategic language agents,...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/06/03/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A01/" title="LLM论文阅读-狼人杀系列 强化学习智能体在狼人杀中的策略玩法"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-03</div><div class="info-item-2">LLM论文阅读-狼人杀系列 强化学习智能体在狼人杀中的策略玩法</div></div><div class="info-2"><div class="info-item-1">#1 Language Agents with Reinforcement Learning for Strategic Play in the Werewolf GameAuthors: Zelai Xu, Chao Yu, Fei Fang, Yu Wang, Yi Wu Agents built with large language models (LLMs) have shown great potential across a wide range of domains. However, in complex decision-making tasks, pure LLM-based agents tend to exhibit intrinsic bias in their choice of actions, which is inherited from the model’s training data and results in suboptimal performance. To develop strategic language agents,...</div></div></div></a><a class="pagination-related" href="/2025/06/16/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A04/" title="LLM论文阅读-狼人杀系列4 利用多智能体强化学习训练社交推理语言模型"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-16</div><div class="info-item-2">LLM论文阅读-狼人杀系列4 利用多智能体强化学习训练社交推理语言模型</div></div><div class="info-2"><div class="info-item-1">Training Language Models for Social Deduction with Multi-Agent Reinforcement LearningAuthors: Bidipta Sarkar, Warren Xia, C. Karen Liu, Dorsa Sadigh Communicating in natural language is a powerful tool in multi-agent settings, as it enables independent agents to share information in partially observable settings and allows zero-shot coordination with humans. However, most prior works are limited as they either rely on training with large amounts of human demonstrations or lack the ability to...</div></div></div></a><a class="pagination-related" href="/2025/06/12/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A03/" title="LLM论文阅读-狼人杀系列 Werewolf 一个直观的游戏框架，配备文本转语音功能以提升用户参与度"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-12</div><div class="info-item-2">LLM论文阅读-狼人杀系列 Werewolf 一个直观的游戏框架，配备文本转语音功能以提升用户参与度</div></div><div class="info-2"><div class="info-item-1">Werewolf: A Straightforward Game Framework with TTS for Improved User Engagement  Authors: Qihui Fan, Enfu Nan, Wenbo Li, Lei Lu, Pu Zhao, Yanzhi Wang The growing popularity of social deduction game systems for both business applications and AI research has greatly benefited from the rapid advancements in Large Language Models (LLMs), which now demonstrate stronger reasoning and persuasion capabilities. Especially with the raise of DeepSeek R1 and V3 models, LLMs should enable a more...</div></div></div></a><a class="pagination-related" href="/2025/06/16/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A05/" title="LLM论文阅读-狼人杀系列5 Werewolf Arena"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-16</div><div class="info-item-2">LLM论文阅读-狼人杀系列5 Werewolf Arena</div></div><div class="info-2"><div class="info-item-1">Werewolf Arena: A Case Study in LLM Evaluation via Social Deduction Authors: Suma Bailis, Jane Friedhoff, Feiyang Chen This paper introduces Werewolf Arena, a novel framework for evaluating large language models (LLMs) through the lens of the classic social deduction game, Werewolf. In Werewolf Arena, LLMs compete against each other, navigating the game’s complex dynamics of deception, deduction, and persuasion. The framework introduces a dynamic turn-taking system based on bidding,...</div></div></div></a><a class="pagination-related" href="/2025/06/16/%E7%8B%BC%E4%BA%BA%E6%9D%80/" title="基于大语言模型（LLM）驱动的AI狼人杀综述"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-16</div><div class="info-item-2">基于大语言模型（LLM）驱动的AI狼人杀综述</div></div><div class="info-2"><div class="info-item-1">基于大语言模型（LLM）驱动的AI狼人杀综述1. 引言狼人杀（Werewolf）是一款经典的社会推理游戏，其核心特点在于隐藏角色、信息不完全以及复杂的社会互动 。玩家必须仅凭口头交流和观察到的行为来推断他人的真实身份，这要求参与者具备战略性决策、说服能力和欺骗能力 。游戏通常在夜晚和白天交替进行，始于夜晚阶段。在夜晚，狼人秘密选择受害者进行淘汰，而预言家和女巫等特殊角色则执行各自的独特能力 。白天阶段，幸存玩家进行公开讨论，随后集体投票淘汰一名被怀疑的狼人 。游戏胜负取决于狼人是否全部被淘汰（村民阵营获胜），或狼人数量达到或超过剩余村民数量（狼人阵营获胜）。  狼人杀作为人工智能（AI）研究的测试平台，其价值非凡。它提供了一个理想的框架，用于评估AI在复杂社会环境中的能力，因为它天然依赖于自然语言沟通、战略性推理、欺骗检测和动态协作 。与国际象棋或围棋等完全信息博弈不同，狼人杀的信息不完全性和自由形式的语言空间引入了显著的复杂性，并拓展了战略可能性，使其成为衡量先进AI能力的独特且具有挑战性的基准 。 传统AI在完全信息博弈（如国际象棋和围棋）中取得了显著成功...</div></div></div></a><a class="pagination-related" href="/2025/06/03/MCP-RAG/" title="LLM论文阅读:RAG-MCP：通过检索增强生成技术缓解大型语言模型工具选择中的提示膨胀问题"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-03</div><div class="info-item-2">LLM论文阅读:RAG-MCP：通过检索增强生成技术缓解大型语言模型工具选择中的提示膨胀问题</div></div><div class="info-2"><div class="info-item-1">RAG-MCP: Mitigating Prompt Bloat in LLM Tool Selection via Retrieval-Augmented Generation [PDF5] [Copy] [Kimi19] [REL]Authors: Tiantian Gan, Qiyao Sun Large language models (LLMs) struggle to effectively utilize a growing number of external tools, such as those defined by the Model Context Protocol (MCP)\cite{IntroducingMCP}, due to prompt bloat and selection complexity. We introduce RAG-MCP, a Retrieval-Augmented Generation framework that overcomes this challenge by offloading tool...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/images/head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">QianLi Yang</div><div class="author-info-description">不定时更新程序员成长之路~</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">17</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/YangQianli92" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:chainllie92@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/Serein_Young" target="_blank" title="Wechat"><i class="fab fa-weixin"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/18/%E6%A2%A6%E5%B9%BB%E8%A5%BF%E6%B8%B8%E4%BD%93%E9%AA%8C%E6%8A%A5%E5%91%8A/" title="无标题">无标题</a><time datetime="2025-06-18T13:53:18.873Z" title="发表于 2025-06-18 21:53:18">2025-06-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/18/%E6%A2%A6%E5%B9%BB%E8%A5%BF%E6%B8%B8/" title="AI赋能《梦幻西游手游》内挂：利用大语言模型与智能体实现玩家托管自动化">AI赋能《梦幻西游手游》内挂：利用大语言模型与智能体实现玩家托管自动化</a><time datetime="2025-06-18T12:44:48.000Z" title="发表于 2025-06-18 20:44:48">2025-06-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/16/%E7%8B%BC%E4%BA%BA%E6%9D%80/" title="基于大语言模型（LLM）驱动的AI狼人杀综述">基于大语言模型（LLM）驱动的AI狼人杀综述</a><time datetime="2025-06-16T09:31:08.000Z" title="发表于 2025-06-16 17:31:08">2025-06-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/16/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A04/" title="LLM论文阅读-狼人杀系列4 利用多智能体强化学习训练社交推理语言模型">LLM论文阅读-狼人杀系列4 利用多智能体强化学习训练社交推理语言模型</a><time datetime="2025-06-16T04:46:48.000Z" title="发表于 2025-06-16 12:46:48">2025-06-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/16/LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8B%BC%E4%BA%BA%E6%9D%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A05/" title="LLM论文阅读-狼人杀系列5 Werewolf Arena">LLM论文阅读-狼人杀系列5 Werewolf Arena</a><time datetime="2025-06-16T04:46:48.000Z" title="发表于 2025-06-16 12:46:48">2025-06-16</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By QianLi Yang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>